,Job ID,URL,Job Title,Job Type,Company Name,Job Location,Job Level,Job Industry,Min Salary,Max Salary,Salary Paid,Date Posted,Contract,Internship,Temporary,Permanent,Job Description,Job Requirements
40,ee50f6e8e7c6e3e3553fab0195ede28c,https://www.mycareersfuture.sg/job/project-manager-saksoft-ee50f6e8e7c6e3e3553fab0195ede28c,Project Manager,Full Time,SAKSOFT PTE LIMITED,"SIM LIM TOWER, 10 JALAN BESAR 208787",Manager,"Banking and Finance, Telecommunications",6000,8000,Monthly,28 Jan 2019,0,0,0,0," Prefer DWH/ETL/Informatica experience Managed/Supervised a small team of developers(under 5) and oversee daily activities to deliver solutions in support of Business Familiarity with SDLC lifecycle as well as Agile/Scrum/Lean methodologies   Strong communication and collaboration skills, have experience working in big projects /programmes(concurrent multiple projects) with multiple stakeholders/customers as well supporting parties Possess strong problem solving skills ,has keen eye for details ,quality consciousness  and actively uses initiative to creatively resolve issues or improve internal processes  ", Minimum 7 years relevant project management experience and delivery of IT application projects Bachelor Degree in Computer Science (or equivalent experience); Good interpersonal and communication skills Able to work independently and as a team 
41,896c46d5418ec90bcb22f28bbd2c9710,https://www.mycareersfuture.sg/job/opening-fatca-saksoft-896c46d5418ec90bcb22f28bbd2c9710,Opening for FATCA,Permanent,SAKSOFT PTE LIMITED,"SIM LIM TOWER, 10 JALAN BESAR 208787",Executive,Information Technology,5500,8000,Monthly,28 Jan 2019,0,0,0,1," The candidate should be well versed with various Regulatory report Experience FATCA and/or iFRS9 ETL Informatica, is an added advantage      ",  candidate should be able to independently file various statutory reports. The candidate should be from Banking / Financial Services ONLY.   
42,7007d5409cdf7c35b60fd75badff954b,https://www.mycareersfuture.sg/job/data-analyst-futurex-technologies-7007d5409cdf7c35b60fd75badff954b,Data Analyst,Contract,FUTUREX TECHNOLOGIES PTE. LTD.,"GERMAN CENTRE, 25 INTERNATIONAL BUSINESS PARK 609916",Executive,Information Technology,6000,6500,Monthly,28 Jan 2019,1,0,0,0,"The successful candidate will be responsible for Global Banking(GB) and Commercial Banking(CB) Analytics, which will include data sourcing, data transformation, predictive modelling and creating Tableau dashboards. Create strong blending data capabilities within team so that we can come up with useful client information from data very quickly Engage with business stakeholders cross countries and gather requirement and liaise with ETL team to get the required data preparation. Promote analytics driven decision making processes across multiple segments/product portfolios Engage and execute the dashboards on Tableau or similar visualization tools Explore statistical and automation tools like R, SAS, Python for predictive and prescriptive analytics Engage relevant technology teams to embed advanced statistical tools Prepare and/or contribute to regular updates for various committees and governance forums Provide insights to senior management and the network based on MIS and analytics Highlight any perceived risks and early alerts to the management based on data analytics Perform data validation and dashboard performance optimization","A proven track record with 4 years or more of relevant analytics work experience and demonstrated career progression/increase in responsibilities Strong academic record: Degree in Finance, Statistics, Computer Science or related field Knowledge of either SAS, R or Python Strong understanding of Hadoop Database Strong Knowledge of Tableau or similar visualization tools Proficient in excel and SQL Knowledge of statistical modelling and machine learning will be an added plus Understanding of the ETL process Highly effective verbal and written English communication skills Good presentation, time management, negotiation and influencing skills Ability to influence without authority Strong analytical and problem solving skills Experience in project management from business requirement definition, solution validation, user testing, technical documentation and production roll out Ability to manage multiple work streams with strong problem solving and analytical skills Strong communication and presentation skills to varying levels of management  "
43,fba95c7774cb8a6e2651a35483eb8569,https://www.mycareersfuture.sg/job/lead-consultant-ncs-fba95c7774cb8a6e2651a35483eb8569,Lead consultant,Permanent,NCS PTE. LTD.,"NCS HUB, 5 ANG MO KIO STREET 62 569141",Professional,Information Technology,7000,10000,Monthly,28 Jan 2019,0,0,0,1," Development of data architecture, strategy and governance to support business, application, security and technology strategic analysis and decision making   Assessment of current and target states of the data architecture to align with strategic or tactical objectives and to develop recommendations to close the gaps   Integrate cloud and on premise data warehouses and data lakes with metadata management, for powerful data-driven solutions   Provides consultancy to clients in areas of data governance to improve quality and control in the management and usage of data. Helps help defines standards, processes and adopts best practices in data management.  Presents roadmaps and architecture landscapes to senior stakeholders to fulfill the organization’s data science, cognitive, analytics and reporting requirements   Evaluation of data related technologies, and defining best practices in the assessments of standards, tools and methodologies including ETL development, to perform hands on data analysis   Create innovations in both analytic algorithms and methodologies with business impact. Responsible for the end-to-end process of analytical solutioning, involving conceptualization and business engagement   Ensures data quality and performs data cleansing to ensure a single source of truth, to enable data as a service for business units and front-end applications to consume   Perform quality review of data modeling design and deliverable, leading work sessions and deliverable presentations with business stakeholders   Manage architecture and technology governance committee agenda to ensure data, security and technology requirements aligned to enterprise standards and policies "," Bachelors or Master’s Degree in Computer Science, Information Technology, or equivalent At least 5 years design & development experience in enterprise data warehousing and analytics projects Expert in Oracle, MSSQL, MYSQL database technologies Best practices using data solutions using Hadoop, Cloudera, Spark, Kafka, MongoDB, NoSQL, Cassandra, Graph, etc Familiar with Tableau, Microstrategy, Qlikview, Informatica, Hortonworks, Talend, Hive and HBase   Understands machine learning, statistics, natural language processing, sentiment analysis, graph analysis, augmented and virtual reality   Proficient in handling complex technical development concepts, latest software tools and technologies, strong database concepts and designing techniques   Excellent in working effectively in a multi-tasking environment, ability to prioritize competing tasks   Fluency and efficiency in creating technical architecture documentation, presentations and stakeholder pitches   TOGAF or other industry recognized architecture certifications preferred "
44,09c037328fd2d76b67d47d6a0c1f90cc,https://www.mycareersfuture.sg/job/head-data-engineering-fixed-mobile-09c037328fd2d76b67d47d6a0c1f90cc,Head of Data Engineering,"Permanent, Full Time",FIXED & MOBILE PTE. LTD.,"ANSON HOUSE, 72 ANSON ROAD 079911",Senior Management,Information Technology,8000,11000,Monthly,28 Jan 2019,0,0,0,1,"TransferTo operates a leading global digital value services network offering safe, reliable and more accessible mobile value services for emerging markets. Our B2B cross-border network interconnects and provides mobile operators, money transfer operators, retailers, distributors, NGOs and corporates with unparalleled infrastructure and reach to offer solutions that better connect loved ones across borders.   A career with TransferTo provides invaluable experience in an exciting and rapidly expanding market and an opportunity to be part of a truly global company with 7 offices worldwide and a workforce that includes over 50 different nationalities.   The Engineering team is responsible for maintaining, building and expanding the core platform of TransferTo in a highly available environment, processing millions of transactions per month. Ensuring scalability, redundancy, security and performance at the same time while enabling multiple external and internal services and APIs to communicate together is one of the key challenges of our team. Connected to hundreds of partners all over the world via various APIs and protocols our platform is unique and delivers the best-in-class product to our customers.   We are seeking an energetic and passionate Head of Data Engineering to help build the robust foundations that will support current and future data-intensive computations across the company. You will be working closely with the Infrastructure, Software Development, Product, Business Intelligence and Data Science teams to provide insight and expertise. You will have the opportunity to shape our data stack, ensuring that our ever-flowing data is adequately collected, organized and made accessible for advanced analytics and beyond.   Key Role Responsibilities  Define our data engineering and data processing strategy to serve business needs Conceive, develop, monitor and optimize reliable data pipelines that convert data into insights Understand the bigger picture when it comes to data processing and use cases across the company Build a reliable, scalable and efficient cloud-based data processing platform and applications to support the different needs Play a central role in delivering our next generation real-time, big data platform Be involved in whole data platform development process including infra, data ETL and service implementation Participate in the design, discussions and technology choices of the on-going major developments with the other teams ","Essential Experience  More than 5 years of experience in data engineering and people management Advanced knowledge of real-time data streams, ETL processes and how to clean, structure and manage sensitive data effectively Strong development skills in some of the following languages: R, Python, Hive, Pig, Mahout, Java, ... Working knowledge of big data concepts like Hadoop, Spark, MapReduce, and HDFS Deep understanding of both SQL and NoSQL data stores Familiar with data tools and services in Azure, AWS, and/or GCP eco-system is preferred Familiar with data management and visualization tools such as Tableau Knowledge of Amazon AWS services and their applications (RDS, Redshift, S3, EC2, ...) Knowledge in RESTful API development Knowledge in CI tools like Jenkins Knowledge in QA processes and automation Coursework in machine learning, data science, data mining, big data, and/or statistical inference is a plus Comfortable with GIT version control Excellent written and verbal communication skills in English A DevOps attitude - you build it, run it & maintain it The ability to execute independently Enjoy learning and adopting new technologies to push the team forward Thrilled to find creative solutions for the challenges you face Finally, wanting to have responsibilities that make a significant contribution and impact on the company "
45,21861e90483b457a87d98b573aeedb8e,https://www.mycareersfuture.sg/job/data-scientist-21861e90483b457a87d98b573aeedb8e,Data Scientist,Full Time,Company Undisclosed,,Non-executive,"Engineering, Manufacturing",3400,6000,Monthly,28 Jan 2019,0,0,0,0,"Responsibilities: Align to, Understand, and Prioritize Analytic Goals to Address Business Opportunities and Value  •  Maintain an intimate understanding of company and department strategy  •  Understand the business objectives in order to develop or establish success criteria metrics  •  Translate business problems into one or more data science projects/solutions    Lead Efforts to Identify Signals in Data that Address Use Cases  •  Understand business processes (data sources and meaning)  •  Manage and optimize data discovery and cleansing  •  Understand and collect relevant data  •  Identify new data sources in the network that will create new insights to business needs  •  Explore relevant data through visualization and statistical methods    Collect, Organize, and Prepare Data for Analysis  •  Work with various volumes of data from multiple disparate sources and perform data analysis and mining to generate solutions to business problems  •  Ensure processes taken to maintain data integrity  •  Understand available data and what data is relevant  •  Collaborate with data architects (IS engineers, BI engineers, DBAs, etc.) to ensure that data needed is available  •  Develop and automate ETL jobs for various volumes of data    Uncover Patterns in Data, Develop Models, and Evaluate Validity of Solutions  •  Develop expertise in data mining and analytic methods  •  Determine statistical validity and significance (pick out signals from noise)  •  Identify and apply appropriate analytical models  •  Evaluate results using statistical methods and improve the model where appropriate  •  Develop predictive models    Deploy Data Science Models into Business Processes  •  Present findings and deliver recommendations using effective presentation and data visualization techniques  •  Collaborate with software engineers to deploy data science solutions into production applications  •  Ensure that the models are easy to support and maintain  •  Regularly review deployed models and monitor for continual improvement  •  Validate that the business value has been met",Requirements:  Doctorate Degree or equivalent experience in Statistics/Physics/Computer Science/Engineering/Operations Research/Applied Maths Good knowledge in programming and statistics. Excellent code writing abilities. Experience in Data-mining and yield analysis. Experience in developing application and data-source in Hadoop big data platform will be advantageous. 
46,d811457c351ebac1d6c04c22a4681965,https://www.mycareersfuture.sg/job/mct-big-data-senior-engineer-d811457c351ebac1d6c04c22a4681965,MCT Big Data Senior Engineer,"Permanent, Full Time",Company Undisclosed,,Non-executive,"Engineering, Manufacturing",5000,10000,Monthly,28 Jan 2019,0,0,0,1,"Do you have a broad theoretical and practical understanding of data engineering and data science? Can you wrangle large scale multidimensional data effectively? Are you always curious to learn something new? Do you love to solve engineering puzzles and optimize complex systems? Can you translate an idea in to an algorithm and make it into a product with quality and scalability in mind? Are you looking for window to the world ?   If so, you may be a great candidate for an Manufacturing Central Team (MCT) Data Engineer position at company, a global, Fortune 500 leader in the semiconductor industry. This position will be based in Singapore.   As an MCT Data Engineer at company, you will:   * Work with an international team of data scientists, data engineers, software engineers, process and equipment engineers, process integration engineers, yield enhancement engineers, R&D, etc. in a collaborative manner to develop new data science solutions that improve quality, improve yield, reduce deviations, improve manufacturing cycle time, reduce cost, extend manufacturing capabilities, etc. * Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments (DOE), visualization, etc. to discover insightful patterns in semiconductor manufacturing data * Work on projects and develop solutions that would be of high impact to various areas at all manufacturing fabs * Deliver polished presentations of data acquisition, data flow, data preparation and data presentation layer to internal customers and leaders to inform business strategy, streamline operations, and execute to revenue goals * In short, be a full-stack data engineer who can take an idea, access and prepare necessary data, work with data scientists to create machine learning models, develop it to an application with intuitive user interface, integrate with any pre-existing systems, demonstrate successful use cases and wins, etc.   Responsibilities and Tasks include, but not limited to:   * Understanding business needs and strategy to develop data science solutions * Collaborating with other data engineers and business process experts to access existing data in data warehouse and big data environments * Developing new or enhancing prior data acquisition and ETL pipelines from various sources into big data ecosystem. * Preparing data for machine learning using appropriate steps and methods, which may include data cleaning, transformation, augmentation, enrichment, sampling, etc. * Working with various scientific data such as equipment sensor data and logs, image and various types of signals, manufacturing process data, etc. to extract meaningful information for analytics * Creating intuitive user interface for interactive data visualization to explain insights from data * Preparing and delivering powerful presentations with rich data visualizations and meaningful business conclusions * Documenting the train of thoughts used to design and implement solutions along with managed source code * Traveling and participating in various internal forums for strategy building and to build solutions in collaboration with various manufacturing sites","Qualifications and Experience: * B.S degree or M.S. degree with 2 years’ experience in Computer Engineering, Industrial Engineering, or any other discipline with extensive programming or machine learning work  * Minimum 2 years of experience working in big data and data science projects and teams * Extensive experience with Java, Scala, Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) is a must * Extensive experience with at least one relational databases (MS SQL, Oracle, MySQL, Teradata, etc.) is a must * Experience with building analytical web applications and data visualization technologies (Django, Javascript, Bootstrap, D3, etc.) is a plus * Good grasp of statistical and scientific programming packages in Python, R, etc. * Good grasp of data science concepts with emphasis on machine learning techniques is a plus * Experience with image processing (OpenCV, Python PIL, scikit-image, etc.) is a plus * Proficiency with collaborative source code management and documentation tools. (GIT, JIRA, Confluence, etc.) * Strong communication skills (written, verbal and presentation) * Willing to do international travel"
47,165e3137bfd84a80aa511eb2574a2e44,https://www.mycareersfuture.sg/job/mct-big-data-engineer-165e3137bfd84a80aa511eb2574a2e44,MCT Big Data Engineer,"Permanent, Full Time",Company Undisclosed,,Non-executive,"Engineering, Manufacturing",3400,6800,Monthly,28 Jan 2019,0,0,0,1,"Do you have a broad theoretical and practical understanding of data engineering and data science? Can you wrangle large scale multidimensional data effectively? Are you always curious to learn something new? Do you love to solve engineering puzzles and optimize complex systems? Can you translate an idea in to an algorithm and make it into a product with quality and scalability in mind? Are you looking for window to the world ?   If so, you may be a great candidate for an Manufacturing Central Team (MCT) Data Engineer position at company, a global, Fortune 500 leader in the semiconductor industry. This position will be based in Singapore.   As an MCT Data Engineer at company, you will:   * Work with an international team of data scientists, data engineers, software engineers, process and equipment engineers, process integration engineers, yield enhancement engineers, R&D, etc. in a collaborative manner to develop new data science solutions that improve quality, improve yield, reduce deviations, improve manufacturing cycle time, reduce cost, extend manufacturing capabilities, etc. * Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments (DOE), visualization, etc. to discover insightful patterns in semiconductor manufacturing data * Work on projects and develop solutions that would be of high impact to various areas at all manufacturing fabs * Deliver polished presentations of data acquisition, data flow, data preparation and data presentation layer to internal customers and leaders to inform business strategy, streamline operations, and execute to revenue goals * In short, be a full-stack data engineer who can take an idea, access and prepare necessary data, work with data scientists to create machine learning models, develop it to an application with intuitive user interface, integrate with any pre-existing systems, demonstrate successful use cases and wins, etc.   Responsibilities and Tasks include, but not limited to:   * Understanding business needs and strategy to develop data science solutions * Collaborating with other data engineers and business process experts to access existing data in data warehouse and big data environments * Developing new or enhancing prior data acquisition and ETL pipelines from various sources into big data ecosystem. * Preparing data for machine learning using appropriate steps and methods, which may include data cleaning, transformation, augmentation, enrichment, sampling, etc. * Working with various scientific data such as equipment sensor data and logs, image and various types of signals, manufacturing process data, etc. to extract meaningful information for analytics * Creating intuitive user interface for interactive data visualization to explain insights from data * Preparing and delivering powerful presentations with rich data visualizations and meaningful business conclusions * Documenting the train of thoughts used to design and implement solutions along with managed source code * Traveling and participating in various internal forums for strategy building and to build solutions in collaboration with various manufacturing sites","Qualifications and Experience: * B.S degree or M.S. degree with 2 years’ experience in Computer Engineering, Industrial Engineering, or any other discipline with extensive programming or machine learning work  * Minimum 2 years of experience working in big data and data science projects and teams * Extensive experience with Java, Scala, Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) is a must * Extensive experience with at least one relational databases (MS SQL, Oracle, MySQL, Teradata, etc.) is a must * Experience with building analytical web applications and data visualization technologies (Django, Javascript, Bootstrap, D3, etc.) is a plus * Good grasp of statistical and scientific programming packages in Python, R, etc. * Good grasp of data science concepts with emphasis on machine learning techniques is a plus * Experience with image processing (OpenCV, Python PIL, scikit-image, etc.) is a plus * Proficiency with collaborative source code management and documentation tools. (GIT, JIRA, Confluence, etc.) * Strong communication skills (written, verbal and presentation) * Willing to do international travel"
48,4b1aeea089cbaa6726eb2cb5dca20fd0,https://www.mycareersfuture.sg/job/senior-etl-data-engineer-smartsoft-4b1aeea089cbaa6726eb2cb5dca20fd0,Senior ETL and DATA Engineer,Full Time,SMARTSOFT PTE. LTD.,"INTERNATIONAL PLAZA, 10 ANSON ROAD 079903",Senior Executive,Information Technology,6000,11000,Monthly,25 Jan 2019,0,0,0,0,"  Responsibilities include understanding ETL & Data Engineering requirements, architecture design, development of etl mapping and framework using SQL, Informatica, Python, Google Bigquery & Google Dataflow. This is a technical position providing hands-on delivery role, working with the cross-functional teams, while ensuring excellent cross functional relationship.   Job Details:  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Work with stakeholders including the BSA, Report developers, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Additional responsibilities include troubleshooting, maintenance, and optimization or enhancement of existing processes. Partner with engineering leads and architects to define & coordinate technical design. Design and code reviews to ensure standards and quality level for the build Performance tuning of ETL jobs to meet SLA Prepare technical documentations on the deliverables Identify, define and implement best practices for process improvements for SDLC management ","Experiences:  Must have 4 to 6 years of experience using SQL, Informatica, Python & Bigquery. Must be hands-on and have working experience in SQL, Informatica 10.x, Python. Working experience with Google Bigquery, Google Dataflow & Exasol is a big plus. Working experience with Kafka or Google Pubsub is a big plus. Hands-on experience in development using best practices and standards on Informatica products specifically PowerCenter 9.x/10.x and Web Service Transformation Solid working skills preferably in Oracle RDBMS, SQL, PL/SQL and ODS/3NF db design considering performance and SLA. Strong design skills with a proven track record of success on large/highly complex projects preferably in the area of Enterprise Apps and Integration. Must have the ability to communicate technical issues and observations. Must have experience in cross functional domain and end to end knowledge of business and technology. Technical and functional knowledge in Oracle EBS & Siebel CRM are preferred.  Must possess excellent verbal and written communication skills. Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables"
49,31003e58ccc2f49ba4d79ddd8a696ca4,https://www.mycareersfuture.sg/job/senior-etl-data-engineer-schellden-global-services-31003e58ccc2f49ba4d79ddd8a696ca4,Senior ETL and Data Engineer,Full Time,SCHELLDEN GLOBAL SERVICES,"INTERNATIONAL PLAZA, 10 ANSON ROAD 079903",Senior Executive,Information Technology,6000,11000,Monthly,25 Jan 2019,0,0,0,0,"Responsibilities include understanding ETL & Data Engineering requirements, architecture design, development of etl mapping and framework using SQL, Informatica, Python, Google Bigquery & Google Dataflow. This is a technical position providing hands-on delivery role, working with the cross-functional teams, while ensuring excellent cross functional relationship.   Job Details:  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Work with stakeholders including the BSA, Report developers, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Additional responsibilities include troubleshooting, maintenance, and optimization or enhancement of existing processes. Partner with engineering leads and architects to define & coordinate technical design. Design and code reviews to ensure standards and quality level for the build Performance tuning of ETL jobs to meet SLA Prepare technical documentations on the deliverables Identify, define and implement best practices for process improvements for SDLC management "," Must have 4 to 6 years of experience using SQL, Informatica, Python & Bigquery. Must be hands-on and have working experience in SQL, Informatica 10.x, Python. Working experience with Google Bigquery, Google Dataflow & Exasol is a big plus. Working experience with Kafka or Google Pubsub is a big plus. Hands-on experience in development using best practices and standards on Informatica products specifically PowerCenter 9.x/10.x and Web Service Transformation Solid working skills preferably in Oracle RDBMS, SQL, PL/SQL and ODS/3NF db design considering performance and SLA. Strong design skills with a proven track record of success on large/highly complex projects preferably in the area of Enterprise Apps and Integration. Must have the ability to communicate technical issues and observations. Must have experience in cross functional domain and end to end knowledge of business and technology. Technical and functional knowledge in Oracle EBS & Siebel CRM are preferred. Must possess excellent verbal and written communication skills. Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables. "
50,99f611ea6cf10ae6754dd32381943bcd,https://www.mycareersfuture.sg/job/senior-etl-data-engineer-schellden-global-99f611ea6cf10ae6754dd32381943bcd,Senior ETL and Data Engineer,Full Time,SCHELLDEN GLOBAL PTE. LTD.,"INTERNATIONAL PLAZA, 10 ANSON ROAD 079903",Senior Executive,Information Technology,6000,11000,Monthly,25 Jan 2019,0,0,0,0,"Responsibilities include understanding ETL & Data Engineering requirements, architecture design, development of etl mapping and framework using SQL, Informatica, Python, Google Bigquery & Google Dataflow. This is a technical position providing hands-on delivery role, working with the cross-functional teams, while ensuring excellent cross functional relationship.   Job Details:  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Work with stakeholders including the BSA, Report developers, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Additional responsibilities include troubleshooting, maintenance, and optimization or enhancement of existing processes. Partner with engineering leads and architects to define & coordinate technical design. Design and code reviews to ensure standards and quality level for the build Performance tuning of ETL jobs to meet SLA Prepare technical documentations on the deliverables Identify, define and implement best practices for process improvements for SDLC management ","Experiences:  Must have 4 to 6 years of experience using SQL, Informatica, Python & Bigquery. Must be hands-on and have working experience in SQL, Informatica 10.x, Python. Working experience with Google Bigquery, Google Dataflow & Exasol is a big plus. Working experience with Kafka or Google Pubsub is a big plus. Hands-on experience in development using best practices and standards on Informatica products specifically PowerCenter 9.x/10.x and Web Service Transformation Solid working skills preferably in Oracle RDBMS, SQL, PL/SQL and ODS/3NF db design considering performance and SLA. Strong design skills with a proven track record of success on large/highly complex projects preferably in the area of Enterprise Apps and Integration. Must have the ability to communicate technical issues and observations. Must have experience in cross functional domain and end to end knowledge of business and technology. Technical and functional knowledge in Oracle EBS & Siebel CRM are preferred. Must possess excellent verbal and written communication skills. Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables. "
51,f3a4815c68088fed7ea9c9136e262e88,https://www.mycareersfuture.sg/job/etl-tech-lead-tata-consultancy-services-asia-pacific-f3a4815c68088fed7ea9c9136e262e88,ETL Tech Lead,Permanent,TATA CONSULTANCY SERVICES ASIA PACIFIC PTE. LTD.,,Executive,Information Technology,5000,9000,Monthly,25 Jan 2019,0,0,0,1," New/Manage DWH Portfolio of applications Application Design, Development, Test, code management & Deployment. Create application Architecture diagram and End-to-End Data Flow Diagrams. Production / Non-Production Deployment support and application Maintenance. Constant discussion with Business and Other Product Processors to derive conclusions on the Design. Follow client change process for both non-Production and Production environment/code changes. Working with Release management for Production release and support. Co-ordinate with L1L2L3 team for Production issues and resolve the DWH Applications issue on time Tracking deadlines, deliverables and timelines throughout the project cycle. "," Degree in Information Technology, Computer or Engineering 6 to 10 years of technical experience in  IBM Infosphere ( DataStage 9.x / 11.x) , Teradata 15.0, Unix Scripting, Oracle 11i, Tivoli Scheduler Good Communication and Interpersonal  skills Knowledge in the SDLC Life Cycle, Agile and Banking Domain Strong knowledge in  IBM Infosphere ( DataStage 9.x / 11.x) , Teradata 15.0, Unix Scripting, Oracle 11i, Tivoli Scheduler Good exposure to Design Patterns & DWH ETL Architecture Addional advantage to have the knowledge in RTC     "
52,640c7a155e09f55c52acc48c3155af1b,https://www.mycareersfuture.sg/job/support-analyst-marks-sattin-640c7a155e09f55c52acc48c3155af1b,Support Analyst,Full Time,MARKS SATTIN (SINGAPORE) PTE. LIMITED,"GUOCO TOWER, 1 WALLICH STREET 078881",Executive,Information Technology,5000,10000,Monthly,25 Jan 2019,0,0,0,0,"• Production services experience in financial services • Incident Management, Problem Management and Request Management • Troubleshooting skills • Previous experience in financial services applications • Unix Shell scripts • Oracle SQL and PL-SQL • Job Scheduling Ctrl M tool • ETL – Informatica • Should be able to work independently","- Experience in L2/L3 Application Enhancement and supporting with Technologies like Informatica, Oracle (PL/SQL), Unix and scheduling tools. - Well aware of Data warehouse concepts and ITIL process in the application support incident/problem/change/release management - Aware  of Agile methodologies.   Interested candidates can click apply for more information. ** We regret to inform that only shortlisted candidates will be notified. ** We respect your privacy and all communication will be treated with confidentiality.  If you wish to know more about this position or explore other roles, please prepare your updated profile and get in touch with our consultants. Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by Manpower for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012.  "
53,96bd91f15d178076670646e3367fec21,https://www.mycareersfuture.sg/job/senior-backend-engineer-manpower-staffing-services-96bd91f15d178076670646e3367fec21,Senior Backend Engineer (West),"Permanent, Full Time",MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"GUOCO TOWER, 1 WALLICH STREET 078881","Professional, Senior Executive",Information Technology,4000,5500,Monthly,25 Jan 2019,0,0,0,1," Develop backend RESTful API for application to serve data analytics engine Build loosely coupled system and deploy it to AWS Deliver software architecture, designs and implementations Integrate system with external platforms from vendor, partner or customer Build API analytics toolkit Build and manage in-house data lake, data ETL pipeline on AWS cloud and software DevOps pipeline Work with different teams in the region and follow good practise in Agile development processes "," Degree in Information Technology / Computer Science / Computer Engineering or equivalent Minimum 4 years' experience in Python and Flask framework to build RESTful API Minimum 4 years' experience in web service development with strong knowledge of Linux ecosystem, Agile, Git and CI/CD pipeline development process Possesses SQL/NoSQL database, queuing system and AWS cloud service experience or knowledge Prior exposure on big scale software projects  Familiar with System/Software Architecture Design, Test Automation Tools & Unit Testing frameworks and Software Documentation "
54,a3683af36b036d1bba755d792f3d7dc2,https://www.mycareersfuture.sg/job/senior-consultant-application-ncs-a3683af36b036d1bba755d792f3d7dc2,"Senior Consultant, Application",Permanent,NCS PTE. LTD.,"NCS HUB, 5 ANG MO KIO STREET 62 569141",Professional,Information Technology,4000,7000,Monthly,25 Jan 2019,0,0,0,1," Development of data architecture, strategy and governance to support business, application, security and technology strategic analysis and decision making   Assessment of current and target states of the data architecture to align with strategic or tactical objectives and to develop recommendations to close the gaps   Integrate cloud and on premise data warehouses and data lakes with metadata management, for powerful data-driven solutions   Provides consultancy to clients in areas of data governance to improve quality and control in the management and usage of data. Helps help defines standards, processes and adopts best practices in data management.  Presents roadmaps and architecture landscapes to senior stakeholders to fulfill the organization’s data science, cognitive, analytics and reporting requirements   Evaluation of data related technologies, and defining best practices in the assessments of standards, tools and methodologies including ETL development, to perform hands on data analysis   Create innovations in both analytic algorithms and methodologies with business impact. Responsible for the end-to-end process of analytical solutioning, involving conceptualization and business engagement   Ensures data quality and performs data cleansing to ensure a single source of truth, to enable data as a service for business units and front-end applications to consume   Perform quality review of data modeling design and deliverable, leading work sessions and deliverable presentations with business stakeholders   Manage architecture and technology governance committee agenda to ensure data, security and technology requirements aligned to enterprise standards and policies "," Bachelors or Master’s Degree in Computer Science, Information Technology, or equivalent At least 5 years design & development experience in enterprise data warehousing and analytics projects Expert in Oracle, MSSQL, MYSQL database technologies Best practices using data solutions using Hadoop, Cloudera, Spark, Kafka, MongoDB, NoSQL, Cassandra, Graph, etc Familiar with Tableau, Microstrategy, Qlikview, Informatica, Hortonworks, Talend, Hive and HBase   Understands machine learning, statistics, natural language processing, sentiment analysis, graph analysis, augmented and virtual reality   Proficient in handling complex technical development concepts, latest software tools and technologies, strong database concepts and designing techniques   Excellent in working effectively in a multi-tasking environment, ability to prioritize competing tasks   Fluency and efficiency in creating technical architecture documentation, presentations and stakeholder pitches   TOGAF or other industry recognized architecture certifications preferred "
55,e9183e59ca005921561c8c9e58b92d74,https://www.mycareersfuture.sg/job/data-modeler-teradata-e9183e59ca005921561c8c9e58b92d74,Data Modeler,Permanent,TERADATA (SINGAPORE) PTE. LTD.,"SUNTEC TOWER THREE, 8 TEMASEK BOULEVARD 038988",Executive,Information Technology,7000,9500,Monthly,25 Jan 2019,0,0,0,1,"   The Data Modeler is responsible for transforming business information into logical data models and for managing the enterprise data model. The emphasis within this position is on the modeling of the business, required for a successful Information Management environment across the Unified Data Architecture. Communication skills are essential as the current data modeling focuses on the interaction with the business on that what needs to be modeled. Consequentially, the Data Modeler is proficient in industry standard techniques for process modeling and data modeling.     Within data modeling, the Data Modeler is proficient in 3rd normal form relational modeling as well as dimensional modeling. Experience with alternate modeling techniques such as Data Vault, and key modeling as it relates to Big Data would be a strong added value. A Data Modeler understands semantic modeling requirements and concepts, and when working with associated Teradata Consultants, can design and document semantic models that are required for specific applications. The Data Modeler is also familiar with new and emerging data which contributes to behavioural or interaction data. This may include modeling for documents, XML, JSON, meta tags (audio, video, pictures) and others. This role will be experienced in group facilitation with participants from diverse business functions and work skills.    Subject areas   Design and normalize the logical data model to third normal form. Facilitate the discovery of entities, attributes, relationships, and business rules from the functional experts and the user community. Prepare fully refined data models in accordance with the guidelines/conventions of Integration DEFinition (IDEF) or equivalent methodology. Develop and manage data models and associated metadata for the enterprise. Work with all related consultants to design and document semantic models. Work with consultants to translate Logical Data Models and Semantic Models into their physical representations. Enhance new and existing logical models with entities to represent client specific models. Work with ETL consultants to map source system data to physical data models. Maintain and publish project business rules and the associated enterprise data dictionary. Evaluate access paths for data which spans multiple deployed technologies; provide recommendations for optimizations in accessing these heterogeneous relationships.   ","Qualifications  Master’s Degree/Bachelor’s, preferably in an Information Technology (IT) related degree 3-5 years of experience with data modeling methodologies and techniques Demonstrable affinity with business processes and business information models Good communication and interpersonal skills      Preferred Knowledge  Logical data modeling Experience with Industry Data Models is a prerequisite Facilitation and conflict resolution processes Architecture Principles, Advocated Positions, Design Patterns, and Implementation Alternatives "
56,b1a72f2482331284f984fb29cca3c64c,https://www.mycareersfuture.sg/job/etl-pl-sql-developer-b1a72f2482331284f984fb29cca3c64c,ETL PL / SQL Developer  (Ref 22844),"Contract, Full Time",Company Undisclosed,,Executive,Information Technology,4500,9000,Monthly,25 Jan 2019,1,0,0,0,"- Design, develop, and configure software systems to meet market and/or client requirements either end-to-end from analysis, design, implementation, quality assurance (including testing) etc",- Degree in Computer Science or similar field.  - At least 2-3 years relevant experience in PL/SQL Programming  - Experienced in Data ETL   Licence No: 12C6060
57,968fdf166eb36d05bdec84ccef6ce232,https://www.mycareersfuture.sg/job/etl-pl-sql-developer-968fdf166eb36d05bdec84ccef6ce232,ETL PL / SQL Developer  (Ref 22844),"Contract, Full Time",Company Undisclosed,,Executive,Information Technology,3000,6000,Monthly,25 Jan 2019,1,0,0,0,"- Design, develop, and configure software systems to meet market and/or client requirements either end-to-end from analysis, design, implementation, quality assurance (including testing) etc",- Degree in Computer Science or similar field.  - At least 2-3 years relevant experience in PL/SQL Programming  - Experienced in Data ETL   Licence No: 12C6060
58,b439604f5e1733831545a25544f69711,https://www.mycareersfuture.sg/job/svp-consumer-finance-technology-cbg-technology-to-dbs-bank-b439604f5e1733831545a25544f69711,"SVP, Consumer Finance Technology, CBG Technology, T&O (190000EW)",Permanent,DBS BANK LTD.,"MARINA BAY FINANCIAL CENTRE, 12 MARINA BOULEVARD 018982",Senior Management,Information Technology,10000,20000,Monthly,24 Jan 2019,0,0,0,1,"Business Function  Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.  Job Purpose  Niche engineering team comprising of architects, designers, development engineers and automation engineers. The team will be responsible for re-engineering next-gen banking products in Cards and Unsecured Loans (UL) segment. Collectively the team should be able to Design and Develop products by collaborating with Business Systems Analysts (also part of the team), selecting the best technology and architecture for the problem at hand. We are looking for problem solvers who apply best engineering practices to software development and own the outcome.  Responsibilities   Extensive experience in Java, JavaScript, Spring boot, Hibernate, Eclipse, JUnit, Apache, Open Source stacks and Linux (Scripting and Shell). Prior experience with Mainframes preferable Experienced in ETL, Legacy modernization Well versed with hands-on development, design using SOA/Microservices Proven experience in design and development of APIs using API Gateways including Gateway deployment, configuration, policy development, migration, debugging and troubleshooting Working knowledge of Web API, REST, XML, JSON, Security (such as OAuth, OpenID Connect)  Ability to work with Linux OS to deploy and configure components Optional - Hands-on design and development experience in TIBCO suite of BW, BPM, BE, EMS, Hawk, and Adapters etc.  Beneficial – Python, Kafka, Hadoop and Spark Cloud based Development (PCF/AWS) Experienced in CI/CD Cross functional/cross technical knowledge about ETL, Data analytics, UI development "," 7+ years, Extensive experience in Java, JavaScript, Spring boot, Hibernate, Eclipse, JUnit, Apache, Open Source stacks and Linux (Scripting and Shell) Willing to research and innovate on various data requirements (Transformation/Processing) Well versed with hands-on development, design using SOA/Microservices Proven experience in design and development of APIs using API Gateways including Gateway deployment, configuration, policy development, migration, debugging and troubleshooting Working knowledge of Web API, REST, XML, JSON, Security (such as OAuth, OpenID Connect)  Ability to work with Linux OS to deploy and configure AXWAY gateway and other components  Optional - Hands-on design and development experience in TIBCO suite of BW, BPM, BE, EMS, Hawk, and Adapters etc.  Cloud based Development (PCF/AWS) Experienced in CI/CD Solid software engineering experience  Strong analytical and problem-solving skills Strong Java and SQL skills (MariaDB) Excellent written and verbal reasoning and communication skills Ability to lead technical solutions end to end "
59,090975944b3429795727a6eac0005616,https://www.mycareersfuture.sg/job/vp-consumer-finance-technology-cbg-technology-to-dbs-bank-090975944b3429795727a6eac0005616,"VP, Consumer Finance Technology,  CBG Technology, T&O (190000EW)",Permanent,DBS BANK LTD.,"MARINA BAY FINANCIAL CENTRE, 12 MARINA BOULEVARD 018982",Senior Management,Information Technology,10400,18700,Monthly,24 Jan 2019,0,0,0,1,"Business Function  Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.  Job Purpose  Niche engineering team comprising of architects, designers, development engineers and automation engineers. The team will be responsible for re-engineering next-gen banking products in Cards and Unsecured Loans (UL) segment. Collectively the team should be able to Design and Develop products by collaborating with Business Systems Analysts (also part of the team), selecting the best technology and architecture for the problem at hand. We are looking for problem solvers who apply best engineering practices to software development and own the outcome.  Responsibilities   Extensive experience in Java, JavaScript, Spring boot, Hibernate, Eclipse, JUnit, Apache, Open Source stacks and Linux (Scripting and Shell). Prior experience with Mainframes preferable Experienced in ETL, Legacy modernization Well versed with hands-on development, design using SOA/Microservices Proven experience in design and development of APIs using API Gateways including Gateway deployment, configuration, policy development, migration, debugging and troubleshooting Working knowledge of Web API, REST, XML, JSON, Security (such as OAuth, OpenID Connect)  Ability to work with Linux OS to deploy and configure components Optional - Hands-on design and development experience in TIBCO suite of BW, BPM, BE, EMS, Hawk, and Adapters etc.  Beneficial – Python, Kafka, Hadoop and Spark Cloud based Development (PCF/AWS) Experienced in CI/CD Cross functional/cross technical knowledge about ETL, Data analytics, UI development "," 7+ years, Extensive experience in Java, JavaScript, Spring boot, Hibernate, Eclipse, JUnit, Apache, Open Source stacks and Linux (Scripting and Shell) Willing to research and innovate on various data requirements (Transformation/Processing) Well versed with hands-on development, design using SOA/Microservices Proven experience in design and development of APIs using API Gateways including Gateway deployment, configuration, policy development, migration, debugging and troubleshooting Working knowledge of Web API, REST, XML, JSON, Security (such as OAuth, OpenID Connect)  Ability to work with Linux OS to deploy and configure AXWAY gateway and other components  Optional - Hands-on design and development experience in TIBCO suite of BW, BPM, BE, EMS, Hawk, and Adapters etc.  Cloud based Development (PCF/AWS) Experienced in CI/CD Solid software engineering experience  Strong analytical and problem-solving skills Strong Java and SQL skills (MariaDB) Excellent written and verbal reasoning and communication skills Ability to lead technical solutions end to end "
60,962b6b110b66841082656a7f6fc8c7eb,https://www.mycareersfuture.sg/job/market-analyst-grabtaxi-holdings-962b6b110b66841082656a7f6fc8c7eb,Market Analyst (Data),Full Time,GRABTAXI HOLDINGS PTE. LTD.,"OUE DOWNTOWN, 6 SHENTON WAY 068809",Executive,Others,3000,6000,Monthly,24 Jan 2019,0,0,0,0,"Get to Know Our Team: The team dubbed the “cool kids” is unconventional, exciting, and mysterious. We embrace teamwork, diversity, creativity, humor, and diligence.   Get to Know the Role: The team takes on some of the most challenging and fascinating market research in the fields of transport, food delivery, payments, and platform services. We apply both traditional and offbeat techniques to form key analytical perspectives of the ever-changing market. We promote a culture where we enjoy raising the bar constantly for ourselves and others, and that strongly supports the freedom to explore and innovate.   The day-to-day activities:   Use quantitative tools to provide uncover strategic and operational insights on various business verticals, regional markets, competitors, and any aspect of the external environment to help shape key stakeholders' perspectives.   Explore, analyze and aggregate data sets to provide actionable information. Create intuitive visualizations to convey broader these results to key stakeholders. Gather, analyze and disseminate insights.   Explore and create new data sources from time to time to further the team’s information-gathering capabilities.   Market Analyst (Data) is not characterized by the following:   Specializing in ETL, pipelining and other data infrastructure tasks. Though it is common to build and maintain some pipelines, we have a dedicated Data Engineering team for this.   Building, training and deploying machine learning models to production in support of our App. Most production models related to our App are managed by our Engineering and Data Science teams.   Taking an academic approach to Grab’s data. That is handled by our core Data Science team.   Responding to ad-hoc data requests from business teams. Most of the operational dashboards are maintained by our Data Analytics team.  ","The Must-haves:  A Bachelor's degree in any field. Strong foundation in data query/wrangling using SQL, python/R/Scala and data visualisation using tools like Tableau. An attitude of self-motivation, effective time management, and the ability to operate in a dynamic and fast-paced working environment. Experience in business, strategy and/or tech consulting would be an advantage. "
61,0b1ccdcadc755fa323def2cd54f4c37c,https://www.mycareersfuture.sg/job/etl-developer-asiacloud-solutions-0b1ccdcadc755fa323def2cd54f4c37c,ETL Developer,"Permanent, Contract, Full Time",ASIACLOUD SOLUTIONS PRIVATE LIMITED,,"Professional, Executive, Junior Executive, Senior Executive",Information Technology,5000,7500,Monthly,23 Jan 2019,1,0,0,1," Gathering requirements and specifications from users / business stake holders. Design, Develop and Test ETL Mappings, Mapplets, Workflows, Worklets to support business requirements. Perform feasibility, impact analysis and suitable solutions based on the use cases. Ensuring data management and governance to maintain the data integrity. Develop data mappings to extract the data from XML/Database and loading to the source stating database tables. Create shell scripts for ETL purpose. "," Degree in Computer Science/IT or equivalent. Relevant working experience in ETL, Informatica PowerCenter, SQL, PowerShell scripting, Databases, Unix Shell etc. Knowledge in the Data Warehousing Domain. Good understanding of RDBMS databases. Good exposure to different Data Modelling techniques. Familiar with Waterfall & Agile methodologies. Understand different interface files. Strong written and communication skills. "
62,1b585050532bdd76ad9421adc07b5a92,https://www.mycareersfuture.sg/job/python-etl-big-data-engineer-cxa-group-1b585050532bdd76ad9421adc07b5a92,Python ETL & Big Data Engineer,Full Time,CXA GROUP PTE. LIMITED,"HAW PAR TECHNO CENTRE, 401 COMMONWEALTH DRIVE 149598",Professional,Information Technology,6000,8000,Monthly,23 Jan 2019,0,0,0,0,"In this role, you would be responsible for:  Creating and maintaining robust ETL jobs Ensuring easy access to the data for the various data consumers Providing solutions for different storage and processing-related issues Contributing to the design of the company’s Data Architecture ","Requirements  Strong Python skills (including Pandas, SQLAlchemy) Proven ability to work efficiently with databases: SQL / NoSQL Experience with Hadoop / Spark is a strong plus Knowledge in Machine Learning - Optional Experience with Web and Front-end tools - Optional Strong software culture is very recommended Ability to express ideas clearly in writing and verbally University graduate with Engineering Degree Native Speaker / Full Fluency English "
63,cb57ab380b51495136aafaf4d33098c3,https://www.mycareersfuture.sg/job/senior-software-developer-charterhouse-cb57ab380b51495136aafaf4d33098c3,Senior Software Developer,Contract,CHARTERHOUSE PTE. LTD.,"BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908",Executive,Information Technology,5500,8250,Monthly,23 Jan 2019,1,0,0,0," Creating ETL mappings to extract data from multiple legacy systems;  Transforming and loading the data into the Enterprise Data Warehouse using Informatica; . Developing complex ETL programs using Informatica Power Center Transformations such as Informatica Aggregator, Sorter, Router, Filter, Joiner, Lookup, mapplet, SQL transformation, Stored Procedure and other transformations;  Setting up batches and work flow sessions to run these mappings;  	Designing Informatica mappings and data model structural changes;  	Designing and creating transformer models;  Developing and optimizing complex SQL programs and writing SQL queries, stored procedures, database triggers, cursors, database constraints, in-line views, PL/SQL records and tables;  Understanding business challenges and translating them into process/technical solutions;  Creating documents related to the ETL process; and  	Producing change control documentation.  "," Required experience in the development, implementation, and maintenance of Informatica applications. Preferred Other database design, development, and normalization using Oracle DBMS or Microsoft SQL Server.  EA License no.: 13C6338 I Reg no.: R111035"
64,4ed758dccc67b4e17a7017d8cd33795f,https://www.mycareersfuture.sg/job/assistant-manager-nuhs-academic-informatics-office-value-driven-outcomes-national-university-health-system-4ed758dccc67b4e17a7017d8cd33795f,"Assistant Manager, NUHS Academic Informatics Office, Value Driven Outcomes",Full Time,NATIONAL UNIVERSITY HEALTH SYSTEM PTE. LTD.,1E KENT RIDGE ROAD 119228,Senior Executive,Others,3700,5200,Monthly,23 Jan 2019,0,0,0,0,"As an Assistant Manager in the Academic Informatics Office (AIO), you will be assisting the NUHS Value Driven Outcomes Division on health informatics and data analytics projects to draw insights and facilitate sharing session with users. You are responsible in the following:  To engage users like clinicians to understand clinical indicators requirements, perform data analysis to monitor the indicators and visualize these data by Tableau Dashboard. Plan, manage and implement health informatics and data analytics projects to draw insights and perform predictive and prescriptive analytics using R and Orange Theory. Provide consultative support in visualizing, preparing and manage a variety of both internal and external clinical and operation data. With knowledge in Health IT data analytics, exposure to SQL and other ETL Tools, you will be required to utilize these tools to process relevant data. Ability to present information in clear and actionable manner with expertise in data analysis and organizational programs. Collaborate effectively with diverse groups to provide advice for analytics related matters. "," Minimum Bachelor’s degree in Mathematics, Economics, Computer Science, Information Management or Statistics. A team player with good interpersonal skills, detail-oriented and flexible to work across different areas within the team. Proficient in the use of MS Excel (advance), Data Visualization tools (e.g. Tableau, IDEAs), SQL and R. Strong analytical skills with an ability to apply business logic to design and implement data mining techniques on large data sets. Possess strong problem solving, critical thinking skills and comfortable to work in an ambiguity environment. Working knowledge of data mining and forecasting/predictive modeling tools and techniques will be preferred. Ability to deliver clear, concise reports and presentations/dashboards and articulate observations and recommendations effectively. Have a proven track record of building strong relationships with stakeholders at various levels. Can-do attitude and ability to work independently. "
65,60c011eb6b7af24a6e1597fd7d15b727,https://www.mycareersfuture.sg/job/data-engineer-collabera-technologies-60c011eb6b7af24a6e1597fd7d15b727,Data Engineer,Contract,COLLABERA TECHNOLOGIES PTE. LTD.,"PAYA LEBAR SQUARE, 60 PAYA LEBAR ROAD 409051",Senior Executive,Information Technology,5500,7150,Monthly,23 Jan 2019,1,0,0,0,"Ø  Possess a degree in Computer Science or related fields Ø  At least 8 year of working experience in data engineering on any relevant database technology - Experience in ETL tools, development in Microsoft SQL Server and Microsoft SQL Server Analysis Services (or any similar SQL/OLAP technology) Ø  Good communication skills, able to work independently with minimal supervision Ø  Good team player as this role will be part of a bigger teamØ ","Ø  Good understanding of data modeling concepts Ø  Experience in Python or Microsoft SQL Server Analysis Services is a plus Ø  Strong understanding of data modeling concepts and good ability to design various components of data model and data engineering solution Able to guide junior team members, review solution design and perform code review"
66,229a0fd289520e8d6e56a3e8bbee01e6,https://www.mycareersfuture.sg/job/consultant-sap-axiom-hcl-singapore-229a0fd289520e8d6e56a3e8bbee01e6,Consultant - SAP Axiom,Permanent,HCL SINGAPORE PTE. LTD.,"AXA TOWER, 8 SHENTON WAY 068811",Executive,Information Technology,5000,6000,Monthly,23 Jan 2019,0,0,0,1,"Maintain live production systems and attend production issues real-time by following customer/hcl standards and processes Involvement in written and oral interfacing with customer Work towards continuous improvement and perform root cause analysis on an ongoing basis. Need to have expertise in SAP Banking Domain and File interface Need to have UNIX and Oracle knowledge Need to work with development team on minor enhancement during releases along with pr-requisite testing in UAT/ Regression systems before deploying to production as per business requirement and automation. Ability to support the Production Apps which are developed  SAP, AXIOM, Portal and basic understanding of ETL process for processing  different upstream files Ability to support user queries with the right spirit and optimal resolution time Ability to work with the team in need and contribute individually wherever required Should be self sufficient to manage the customer expectations Should have good attitude to work in teams when required Good learning abiliity to understand the existing application and propose new ideas To monitor and track tickets/change requests and manage SLAs. To prepare and submit status reports for minimizing exposure and risks on the project or closure of escalations  To develop and guide the team members in enhancing their technical capabilities and increasing productivity To ensure process compliance in the assigned module| and participate in technical discussions/review.  ","Minimum 4 years of SAP Production Support experience in SAP ABAP, MDG, BW, FI and COPA skills. Candidate should be trained and need to have work experience of 1.5 years on AXIOM tool. Ideal candidate should have around 4 yrs exp in Oracle/ UNIX and  basic knowledge on java to support  Portal application Should have more than 4 years support & maintenance project experience.  Need to have good exposure to ITIL processes (Incident, SR, Change and Problem Management). Should have SAP Techno-functional  knowledge (across SAP ABAP, MDG, BW, FI and CO skills)  to identify proactive and reactive improvement ideas and prepare Technical Specific Documents. Prepare various performance metric reports for senior management ""Need to have functional knowledge in SAP Banking Domain like  General Ledger,  Sub Ledger, Reconciliation (FI Vs COPA,  SL Vs GL,  R3  Vs  BW etc), FI & CO document  Reversals, Swinging Balalance Accounting, Mullti currency accounting , Restatement , Period open/ close, Balance carry forward (FI, COPA, Vendor & Customer), Asset depreciation, Vendor / customer migration, Reporting , Trial Balance. BW slots/ Process chain monitoring / report generation/ Cube loading / Open Balance Load"" Expertise in Oracle command  to update/ modify tables. Expertise in AXIOM & UNIX commands to handle backend servers and support Admin activities during dress rehersal, disaster recovery, release, etc. Knowledge on GGL and  FRRR architecture of Deutsche Bank/ SAP Banking Domain/ SAP BW / ETL process Hands on experience in tools such as geneos  and dbunity Technical/Professional Skills SAP ABAP (RICEF), MDG, BW, FI and CO skills for production support SAP Banking Domain knowledge  for production support Knowledge of Web Service (Definition and Configuration) Good understanding of ERP architecture, functionality  for production support Strong understanding and Hands-on experince in support / cordination with SAP BASIS for Release/ Upgrade/ Enhancement / Disaster Recovery / Dress Rehersal/ Archieving/ App Server Housekeeping/ Server Monitoring. Must have knowledge of production support issues/ resolution pertaining to Multi Client SAP production system. Hands-on Oracle and Unix Workflow knowledge of Task & event binding Experience working with external Vendors & Outsourced projects Non-Technical / Soft Skills Excellent analytical & communication skills. Proven ability to work with people from different cultures A high level of intelligence; ability to operate not only on the basis of important past experiences, but in the light of the approaches and developments that occur in the market.  Natural problem solving inclination High level presentation and interpersonal  skills Experience decomposing complex problems into component parts for effective problem solving GOOD to HAVE ·         Expertise in AXIOM Controller View ·         ETL Knowledge and Datawarehousing ·         Bachelors Degree in Engineering ·         ITIL / Problem Management Certified ·         Experience in Team Handling Capabilities"
67,90b10972e11c366f0b79039872a30cb9,https://www.mycareersfuture.sg/job/analyst-national-university-health-system-90b10972e11c366f0b79039872a30cb9,IT Analyst,Full Time,NATIONAL UNIVERSITY HEALTH SYSTEM PTE. LTD.,1E KENT RIDGE ROAD 119228,Senior Executive,Information Technology,3000,4200,Monthly,23 Jan 2019,0,0,0,0,"As an IT Analyst in Academic Informatics Office, you will assist the Medical Informatics & Governance Division by translating user requirements into system technical design, and working closely with team members to deliver quality software programs for data processing, participating in system quality testing and any necessary technical support. You are responsible for the following:   Understand requirements and participate in technical design.  Develop and implement system applications in accordance to user requirements.  Perform user acceptance and system integration testing for quality assurance.  Provide operational support and ongoing maintenance and enhancement after implementation.  Support and be involved in data extractions, ETL Processing and generation of report for analysis. "," Bachelor or Masters in Computer Science/Computer Engineering/IT or equivalent. At least 3 years of experience in developing new applications Strong knowledge of coding practices with involvement in at least 1 full Software Development Life cycle. At least 2 years of experience in Microsoft .Net Development, and familiar with ASP.NET. ADO.NET, C#, WCF, Testing, .NET Framework 3.5, Ajax Framework, MS Visual Studio 2013 (or later), MS SQL 2012 (or later). Experience with windows or web development and familiar with HTML5, CSS3. Strong JavaScript, Python Development experience using prevailing JavaScript and UI Framework such as JQuery,  JQuery mobile, Bootstrap, etc. Experience in PHP, MySQL, responsive web design will be added advantage. Good technical knowledge and experience in Object Orientated design and programming. Strong analytical skills, proactive and a strong team player. Ability to work independently with minimum supervision to meet tight project timelines. "
68,1ae9e5ba19124ca6a5b9233b4177effe,https://www.mycareersfuture.sg/job/informatica-developer-astek-singapore-innovation-technology-1ae9e5ba19124ca6a5b9233b4177effe,Informatica Developer,Permanent,ASTEK SINGAPORE INNOVATION TECHNOLOGY PTE. LTD.,"HONG LEONG BUILDING, 16 RAFFLES QUAY 048581",Executive,Information Technology,6000,9000,Monthly,22 Jan 2019,0,0,0,1,"This role requires a strong, technical, hands-on person focusing on Informatica infrastructure. The successful candidate will be a member of a dynamic IT Architecture team and will work with other Singapore, Hong Kong and regional IT teams.   Direct Responsibilities  The position holder will be:  ·       Working with Business team to understand the requirements. ·       Managing and supporting Informatica in Linux environment. ·       Designing and developing complex Informatica ETL processes that integrate large data sets from multiple sources ·       Loading data warehouse objects including dimensions, hierarchies, fact tables and aggregates ·       Ability to create the metadata layers including physical, semantic and presentation layers ·       Experience with Oracle Data Warehouse Console (DAC)  ·       Loading data into an enterprise data warehouse environment  ·       Developing and maintaining Informatica PowerCenter solutions  ·       Performing systems and data analysis to implement and optimize Informatica mappings and ETL workflows, data flows, shell scripts and stored procedure ·       Ensuring accuracy and integrity of data and applications through analysis, coding, writing clear documentation and problem resolution ·       ETL support experience: monitor, troubleshoot, track and document day-to-day production issues ·       Experience in setting up ETL using Oracle EBS as the data source","Technical and Behavioural Competencies / Specific Qualifications:  ·       At least 5 years of experience of Informatica development. ·       Experience working with a job scheduler application (Autosys) to design and schedule Informatica workflow ·       Experience with RDBMS (Oracle/SQL Server etc) and writing and tuning Oracle SQL and PL/SQL statements ·       Takes initiative and is results driven ·       Strong decision making and analytical skills ·       Act with integrity ·       Ability to manage change and complexity with confidence ·       Strong team player ·       Client focused and commercial thinking ·       Excellent interpersonal and communication skills ·       Self-motivated and genuine interest in Banking and Finance ·       Proficiency in Microsoft office (MS Word, Excel & Power point) ·       Exposure to big data and programming is a plus"
69,e7fdbd896a5575391c8ea2365f3be9a1,https://www.mycareersfuture.sg/job/senior-software-developer-charterhouse-e7fdbd896a5575391c8ea2365f3be9a1,Senior Software Developer,Contract,CHARTERHOUSE PTE. LTD.,"BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908",Executive,Information Technology,6000,8500,Monthly,22 Jan 2019,1,0,0,0," Perform design data model and develop extraction, loading and transformation ETL rules based on requirement Create technical design specification Fine tuning, and optimization of DB & ETL jobs Involve in System Integration test, User acceptance Test, Deployment and warranty support after implementation Ensure data quality throughout the ETL process Lead a team of developers "," Minimum 5 years of experience in Informatica, Teradata and UNIX Experience in ETL tools Hand on Experience on writing Teradata SQL. Should be expert in Teradata Utilities Should be good in Unix Shell scripting Experience in best practice of designing and developing of database, SQL, ETL process, logging, auditing, and error handling Good exposures and experience in Data Profiling and Data Modeling Experience in RDBMS  like Oracle, MS SQL etc Experience in creating test plan, test cases, test scripts and data integration. Experience in scripting Experience in following SDLC / Agile software development methodologies. Experience in banking industry  Please send your resume in word format with your current and expected salary to yvonnet@charterhouse.com.sg EA License no.: 13C6338 I Reg no.: R1110355"
70,33a57fecf0884a5fbbebdc9d67024086,https://www.mycareersfuture.sg/job/senior-datawarehouse-consultant-charterhouse-33a57fecf0884a5fbbebdc9d67024086,Senior Datawarehouse Consultant,Contract,CHARTERHOUSE PTE. LTD.,"BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908",Executive,Information Technology,6000,8000,Monthly,22 Jan 2019,1,0,0,0," Prepare Test cases for pre-UAT, wherever applicable. Represent user for pre-UAT. Validate test results and perform functional testing. Co-ordinate UAT phase with business users and Vendor Data Analysts. Responsible for obtaining UAT sign-off from user. Responsible for conducting user training on Business intelligence platform access layers / Reports.  Experience in SDLC of Datawarehouse Projects from Business Requirements gathering, Data profiling, Data modelling & Mapping, ETL coding and reports creation. Creation of Conceptual, Logical and Physical data models for OLTP and OLAP systems Practice range of options for common ETL design and techniques in data cleansing and optimization for extracting, transforming, cleansing and loading data from various relational and non-relational data sources systems. "," Degree in Statistics, Mathematics, Computer Sciences, or equivalent studies with at least 4 years of data analyst experience in the technological field Sound knowledge of financial service logical data model (Teradata FSLDM). 4 to 6 years of related work experience required. Technical expertise regarding data warehouses is must. Understanding of relational databases; including SQL required. Should have extensive experience in Teradata, ETL, Unix Banking domain experience is a must Should have lead mid to large size team Excellent communication & interpersonal skills Must have experience effectively using communication skills to achieve mutual understanding.  Please send your resume in word format with your current and expected salary to yvonnet@charterhouse.com.sg EA License no.: 13C6338 I Reg no.: R1110355  "
71,e54d9277e0d47cf26b64dbe97dc3b23a,https://www.mycareersfuture.sg/job/senior-software-test-analyst-spencer-ogden-e54d9277e0d47cf26b64dbe97dc3b23a,Senior Software Test Analyst,"Contract, Full Time",SPENCER OGDEN PTE. LTD.,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616",Executive,Information Technology,5000,8000,Monthly,22 Jan 2019,1,0,0,0,We are looking for experienced software testers with prior experience working on Database and ETL testing. ," Relevant qualifications in IT/Computer Science Min 5 - 10 years of experience on Software Development/Testing experience on Data base/ ETL projects Experienced on Test Estimation, Test planning, Test Scenarios preparation, executing Test Cases Documenting & Reporting using HP ALM/ Quality Center, Spira tools (Creating Traceability, executing test cases and generating execution/ defect report from QC.) Well acquainted in testing methodology relative to software deployment life cycle(SDLC) and exposure to all phases of SDLC Experience in large scale custom build projects  "
72,2b1e7cfe58b6a681298840d3f44af017,https://www.mycareersfuture.sg/job/avp-data-engineer-ntuc-link-2b1e7cfe58b6a681298840d3f44af017,"AVP, Data Engineer",Full Time,NTUC LINK PRIVATE LIMITED,,Manager,Information Technology,8000,12000,Monthly,21 Jan 2019,0,0,0,0,"The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance.   As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 SE’s range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&B), LearningHub (training), First Campus(ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. The Data Architecture & Information Management Team will manage and govern the overall datasets of the organization and drive the execution of how the data will be collected, stored, processed and applied across these social enterprises (SEs). In this role you will work with various industries and most diverse datasets in Singapore.   Responsibility:  Define the overall data engineering and ETL frameworks across each SE for the CAO office. Working closely with data scientists and business analysts map out data requirements and data roadmap that will drive the analytical underpinnings for each SE work. Lead a team of 5-7 data engineers, defining the ETL tool kit, build ETL frameworks, manage the governance and SLA for each ETL deployment for analytical teams. Work closely with each SE tech heads and their external vendors in mapping out data fields and data transfer process.  Design, build, support and optimize new and existing data models and ETL processes. Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies. Develop and manage the various dashboards for management decision and data visualizations. Define and manage SLA for all data processes and own data quality issues.   ","Preferred qualification and skills:   Advanced degree in computer science, computer engineering, or other technical fields. 6-10 years’ experience having developed data engineering capabilities for large and complex franchises. Strong data modeling, schema design and SQL development skills. ETL/ELT implementation and data integration. Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc.  Big data platform development (Hadoop/Hive/Hbase/Spark, etc.) REST/Web API development and management. Hands-on experience in any modern programming language (Python or Java preferred). Design pattern, 12-factor app principle and modern cloud architecture. Self-motivated and proactive, willing to learn new things. Good communication skills and strong team player. "
73,fb56874d3392ea8efafd9b0e3cd60d3a,https://www.mycareersfuture.sg/job/pentaho-consultant-fortitude-partnership-fb56874d3392ea8efafd9b0e3cd60d3a,Pentaho Consultant,Permanent,FORTITUDE PARTNERSHIP PTE. LTD.,,Professional,"Consulting , Banking and Finance, Information Technology, Others",,,,21 Jan 2019,0,0,0,1,"Overview: This global business is looking for experienced ETL Consultants to help build and enhance their client’s data capabilities within the banking space. Vacancies for ETL customer support, ETL developers, ETL Technical Consultants","Skills & Responsibilities:  Good understanding of ETL methodologies, approaches, technologies, and architecture. ETL processes Experience in ETL design and options to improve load and extract performance Design, Develop, Test, Optimize and Deploy ETL code and stored procedures to perform all ETL related functions Ability to mentor and perform knowledge transfer to support team  Tools:  Proficient at leveraging the tools and technology to drive value for clients. ETL tools - Pentaho experience would be the preference Database management systems Data modeling tools  Consulting Acumen:  Strong decision making and communication skills Demonstrated ability in engaging and communicating with stakeholders Strong technical, strategic and business skills with the ability to solve complex problems  Industry Experience:  Prior professional experience in a consulting environment or client facing role is preferred, but not required. Knowledge and experience working within Financial Services  Keywords: Pentaho, ETL"
74,6d863115bbd5170f296c2050802a3661,https://www.mycareersfuture.sg/job/senior-software-developer-apar-innosys-6d863115bbd5170f296c2050802a3661,Senior Software Developer,Contract,APAR INNOSYS PTE. LTD.,"SGX CENTRE II, 4 SHENTON WAY 068807",Executive,Information Technology,5500,8250,Monthly,21 Jan 2019,1,0,0,0," Creating ETL mappings to extract data from multiple legacy systems;  Transforming and loading the data into the Enterprise Data Warehouse using Informatica; . Developing complex ETL programs using Informatica Power Center Transformations such as Informatica Aggregator, Sorter, Router, Filter, Joiner, Lookup, mapplet, SQL transformation, Stored Procedure and other transformations;  Setting up batches and work flow sessions to run these mappings;  	Designing Informatica mappings and data model structural changes;  	Designing and creating transformer models;  Developing and optimizing complex SQL programs and writing SQL queries, stored procedures, database triggers, cursors, database constraints, in-line views, PL/SQL records and tables;  Understanding business challenges and translating them into process/technical solutions;  Creating documents related to the ETL process; and Producing change control documentation "," Required experience in the development, implementation, and maintenance of Informatica applications. Preferred Other database design, development, and normalization using Oracle DBMS or Microsoft SQL Server. "
75,02b7bbdde5449f585897ff0d3a039a5c,https://www.mycareersfuture.sg/job/data-integration-support-lead-neurones-asia-02b7bbdde5449f585897ff0d3a039a5c,Data Integration Support Lead,"Permanent, Full Time",NEURONES IT ASIA PTE. LTD.,"TAMPINES PLAZA, 5 TAMPINES CENTRAL 1 529541","Executive, Senior Executive",Information Technology,6000,7000,Monthly,21 Jan 2019,0,0,0,1,"In the context of team expansion, Neurones IT Asia is currently looking for a dynamic and highly competent Data Integration Support Lead for a prestigious client in the luxury retail industry. Exciting opportunities, a competitive package and benefits await the successful candidate. Candidate will lead the Business solution support team and will be working closely with developers and business analysts on a big variety of projects in the luxury retail business. In addition, we are also looking for the potential candidate to have knowledge in webMethods. Candidate will be generating reports for clients, keeping track of shift management and ad hoc duties as and when assigned The candidate will be in charge of:  Responsible for delivering Productivity improvement and Incident / Event reduction; Responsible for shift management Works with internal business and technology staff to accurately gather and interpret requirements, specifications, and database models Supports innovative and optimal data solutions Integrates ETL/ControlM/EAI development with existing codebase to maximize object reuse Documents ETL/ControlM/EAI processes, programs and solutions as per established standards Performs tasks required to conform to the company’s configuration management and software release processes Monitors and administers ETL/ControlM/EAI platform to verify execution and measure performance   ","  3- 5 years+ experience in API Must possess extensive knowledge of webServices, SOAP, REST, Service Oriented Architecture Knowledge of Control-M and Datastage is a must Proficiency in webMethods Knowledge of microservice architecture a big bonus Experience with Oracle solutions, especially XStore or MICROS Retail Xstore Java POS Knowledge in SQL Proficient in converting flat file, XML, and fixed length formats Understanding of model driven development Understanding of ETL best practices Hands-on experience with development best practices Proficient in working with technical and business teams to extract and document data integration/exchange requirements Ability to express complex technical concepts effectively, both verbally and in writing Ability to handle multiple projects and deadlines with minimal supervision "
76,fa02b669ca72951a16a725ef68e4cb61,https://www.mycareersfuture.sg/job/technical-lead-teradata-hcl-singapore-fa02b669ca72951a16a725ef68e4cb61,Technical Lead - Teradata,Permanent,HCL SINGAPORE PTE. LTD.,"AXA TOWER, 8 SHENTON WAY 068811",Executive,Information Technology,7000,8500,Monthly,21 Jan 2019,0,0,0,1,"Study Business requirements and convert the same to Technical Requirements. Sound knowledge of financial service logical data model (Teradata FSLDM) Should be able to create and understand Mapping documents for FSLDM and doswnstream Design Data Modeling based on business requirement  Must have Strong Analysis and Problem Solving Skill Design and document development standards Extensive Experience in Banking Domain Provide solutions for various data and ETL problems Support of SIT/UAT/Regression Testing as well as for Production Lead/guide/motivate Team members, Take the team into Right direction Propose design to create and schedule ETL jobs using Control M Able to handle multiple projects and work under agreesive timeline Should have strong multi tasking Skill and Must be able to work/support on multiple data marts simultaneously Own End to End responsible for Project Delivery Experience in SDLC process Good Communication, Flexibility and commitment  ","Teradata SQL Unix Build ETL Data Pipe using Teradata ETL Teradata Utilities(BTEQ,Fast Load,Multi Load) FSLDM  Control M Business Analysis   GOOD to HAVE Hadoop Eco Systems (Hive,Hbase) Risk and Regulatory project experiecne  Educational Qualification B.E/B.TECH/M.E M.SC(in CS),M.C.A Technical / Professional Skills Complete Software Development Lifecycle experience Good communication and interpersonal skills  "
77,1eef0a8f72f7cfbf77998048fb6b281f,https://www.mycareersfuture.sg/job/solutions-architect-alpha7-consultancy-1eef0a8f72f7cfbf77998048fb6b281f,Solutions Architect,Full Time,ALPHA7 CONSULTANCY PTE. LTD.,"PAYA LEBAR SQUARE, 60 PAYA LEBAR ROAD 409051",Senior Executive,Information Technology,6000,8000,Monthly,21 Jan 2019,0,0,0,0,"Who are we? We are a team of passionate people that came from various industries, both veterans as well as juniors. We value every individual feedback in everything we do. We aim to deliver a high quality product that solves small business problem using Analytics, giving them insights on their day-to-day business.   What we are building? We help small and growing businesses transform in today’s Digital Economy. With our in-house data experts, Alpha7 introduces A7 IoB® (A7 Internet of Business). A7 IoB® is a self-service digital workspace tool, built to empower small and growing business to take charge of their biggest asset: business data. Thus, allowing businesses to use data and make smarter data-driven decisions. Enterprises who are helping SMEs can also leverage A7 IoB® to provide value-added services to their clients. A7 IoB® can:  ✔ Connect your data sources with ease and view your business performance with accuracy.  ✔ Discover business opportunities using data.  ✔ Validate your business decisions with real-time data. If you want to know more about us visit a7iob.com   How would you contribute to Alpha7? As a Solution Architect, you will have a critical role in designing and developing our current SAAS platform. You will in charge of designing core feature of the product, ETL, Data Analysis and several APIs in AWS using microservices. You may also be required to provide technical support & training to our internal sales and operations team. You will report directly to the Technology Director and lead the team during his absence.   Duties and Responsibilities   Design architecture for several components of the platform (ETL, Frontend, APIs…) Design & Implement AWS infrastructure for key component Code complex features Help setup/design development tools & process Train & Coach the team  Successful candidate will have the opportunity to work in any one of the companies under Alpha7 Group.  ","Requirements:  ·         5+ yrs Experience in designing architecture in multi tenant application / SaaS ·         5+  yrs experience designing micro services applications ·         3+ yrs of experience using AWS and Cost optimisation for AWS ·         3+ yrs of experience in Data Analytics – ETL, Data Warehouse, Pandas/Spark/Hadoop ·         Good knowledge of Network & Application Security ·         Good  knowledge of Docker Technology (Kubernetes,  ECS…) ·         Expert in Javascript (node.JS, Angular/React/Ember) ·         Programming experience in Python ·         Good knowledge of Linux and bash scripts   The following are a plus:  ·         Previous experience in Data Analytics Industry ·         Previous experience in leading a  team of developers ·         Experience in Serverless Architecture and implementation ·         Previous experience in technical pre-sales ·          Knowledge of Agile methodology"
78,88c018cd55c2edf7aec32353b73a61a7,https://www.mycareersfuture.sg/job/data-architect-enterprise-architecture-office-avensys-consulting-88c018cd55c2edf7aec32353b73a61a7,"Data Architect, Enterprise Architecture Office",Permanent,AVENSYS CONSULTING PTE. LTD.,"VERTEX, 33 UBI AVENUE 3 408868",Manager,Information Technology,7000,12000,Monthly,21 Jan 2019,0,0,0,1,"Primary Responsibilities  Development of data architecture, strategy and governance to support business, application, security and technology strategic analysis and decision making  Assessment of current and target states of the data architecture to align with strategic or tactical objectives and to develop recommendations to close the gaps Integrate cloud and on premise data warehouses and data lakes with metadata management, for powerful data-driven solutions Be a trusted architect adviser to the management team and also give direction to guide the teams in solution design and implementation, being knowledgeable of data analytics trends Presents roadmaps and architecture landscapes to senior stakeholders to fulfill the organization’s data science, cognitive, analytics and reporting requirements Evaluation of data related technologies, and defining best practices in the assessments of standards, tools and methodologies including ETL development, to perform hands on data analysis Create innovations in both analytic algorithms and methodologies with business impact. Responsible for the end-to-end process of analytical solutioning, involving conceptualization and business engagement Ensures data quality and performs data cleansing to ensure a single source of truth, to enable data as a service for business units and front-end applications to consume Perform quality review of data modeling design and deliverable, leading work sessions and deliverable presentations with business stakeholders Manage architecture and technology governance committee agenda to ensure data, security and technology requirements aligned to enterprise standards and policies Create a digital working experience for Information Management (IM) staff and hold regular TechTalks Engagements to share best of breed technologies in the market  ","Requirements  Bachelors or Master’s Degree in Computer Science, Information Technology, or equivalent • Minimum of 10 years IT experience and 5 years in data architecture, strategy, modeling and tools At least 5 years design & development experience in enterprise data warehousing and analytics projects Expert in Oracle, MSSQL, MYSQL database technologies Best practices using data solutions using Hadoop, Cloudera, Spark, Kafka, MongoDB, NoSQL, Cassandra, Graph, etc Familiar with Tableau, Microstrategy, Qlikview, Informatica, Talend, Hive and HBase Understands machine learning, statistics, natural language processing, sentiment analysis, graph analysis, augmented and virtual reality  Proficient in handling complex technical development concepts, latest software tools and technologies, strong database concepts and designing techniques Excellent in working effectively in a multi-tasking environment, ability to prioritize competing tasks Fluency and efficiency in creating technical architecture documentation, presentations and stakeholder pitches  TOGAF or other industry recognized architecture certifications preferred Clear communicator with excellent oral and written skills and experience interacting with both business and IM individuals at all levels including the executive level Possess the personal attributes of integrity, trust and credibility, hungry for results and show perseverance. A good listener, customer oriented, strong interpersonal skills Creative thinking skills with deep technological expertise, business acumen and software development background "
79,abcc422cbdff6cbee3e26851b6204764,https://www.mycareersfuture.sg/job/data-engineer-ntuc-link-abcc422cbdff6cbee3e26851b6204764,Data Engineer,Full Time,NTUC LINK PRIVATE LIMITED,,Professional,"Engineering, Information Technology",5000,10000,Monthly,21 Jan 2019,0,0,0,0,"The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance.    As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 SE’s range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&B), LearningHub (training), First Campus(ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. The Data Architecture & Information Management Team will manage and govern the overall datasets of the organization and drive the execution of how the data will be collected, stored, processed and applied across these social enterprises (SEs). In this role you will work with various industries and most diverse datasets in Singapore.    Responsibility: ·       As a data engineer, you will be creating, writing and maintaining data transfer process and protocols for the data platform.  ·       Work closely with each SE tech heads and their external vendors in mapping out data fields and data transfer process.  ·       Design, build, support and optimize new and existing data models and ETL processes. ·       Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies. ·       Develop and manage the various dashboards for management decision and data visualizations. ·       Define and manage SLA for all data processes and own data quality issues.  ","Preferred qualification and skills:  ·       Advanced degree in computer science, computer engineering, or other technical fields. ·       6-10 years’ experience having developed data engineering capabilities for large and complex franchises. ·       Strong data modeling, schema design and SQL development skills  ·       ETL/ELT implementation and data integration ·       Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc.  ·       Big data platform development (Hadoop/Hive/Hbase/Spark, etc.) ·       REST/Web API development and management ·       Hands-on experience in any modern programming language (Python or Java preferred) ·       Design pattern, 12-factor app principle and modern cloud architecture ·       Self-motivated and proactive, willing to learn new things ·       Good communication skills and strong team player"
80,f03f4f6fe41d6939bbd04f73c94c7f1f,https://www.mycareersfuture.sg/job/data-analyst-mindtree-f03f4f6fe41d6939bbd04f73c94c7f1f,Data Analyst,Full Time,MINDTREE LIMITED (SINGAPORE BRANCH),"HONEYWELL BUILDING, 17 CHANGI BUSINESS PARK CENTRAL 1 486073",Professional,Information Technology,6000,8000,Monthly,21 Jan 2019,0,0,0,0,"1)    Around 6+ years of IT experience across varied development and support projects. 2)    Deep understanding and experience of working in Data and Analytics projects. 3)    Experience in working as Data Analyst – understanding data inputs and outputs and interfaces with various systems 4)    Experience in working as Business Analyst – understanding Business requirements and mapping the data elements to it and facilitating discussions with business and IT teams 5)    Experience on various ETL, reporting and analytical tools like SAS, Tableau etc. 6)    Project Task Tracking and Status Reporting. 7)    Excellent communication and problem-solving skills. 8)    Strong time management and client management skills.",Same as Job Description
81,1aff851cc4fd39d6a38b9ee85aad235c,https://www.mycareersfuture.sg/job/senior-data-architect-hydrogen-consulting-solutions-1aff851cc4fd39d6a38b9ee85aad235c,Senior Data Architect,Contract,HYDROGEN CONSULTING SOLUTIONS PTE. LTD.,"PRUDENTIAL TOWER, 30 CECIL STREET 049712",Professional,Banking and Finance,9000,12500,Monthly,21 Jan 2019,1,0,0,0,"•    Support the rollout of Tableau and analytics capabilities across GB and CB client on boarding and client life cycle management space. •    Engage with business stakeholders cross countries and gather requirement and liaise with ETL team to get the required data preparation. •    Engage and execute the dashboards on Tableau or similar visualization tools. •    Explore statistical and automation tools like R, SAS, Python for predictive and prescriptive analytics •    Engage relevant technology teams to embed advanced statistical tools   •    Be an ambassador for usage of tools for data driven decision making.  •    Prepare and/or contribute to regular updates for various committees and governance forums. •    Provide insights to senior management and the network based on MIS and analytics. •    Highlight any perceived risks and early alerts to the management based on data analytics.  ","    Degree or Professional Qualification      Experience in rolling out or being part of a data analytics implementation     Knowledge of tableau and similar tools like micro strategy, qlikview etc     Proficient in excel and sql     Knowledge of either R, SAS or Python will be an added plus     Understanding of the ETL process     Highly effective verbal and written English communication skills      Good presentation, time management, negotiation and influencing skills     Ability to influence without authority     Strong analytical and problem solving skills     Strong process mapping skills and process orientation     Knowledge of process improvement methodologies     Proven ability to manage and execute projects to a high degree of excellence within set timelines.     Ability to think laterally and outside the box; able to conceptualize and articulate requirements     Ability to collaborate effectively with a wide range of stakeholders  "
82,0336b06c32382e123bcb09896c9bff67,https://www.mycareersfuture.sg/job/talend-etl-developer-0336b06c32382e123bcb09896c9bff67,Talend ETL Developer,Full Time,Company Undisclosed,,Executive,Information Technology,6500,7500,Monthly,20 Jan 2019,0,0,0,0,A challenging work environment where the selected candidate will perform Talend /Informatica development in a Big data ecosystem.,"5+ Years of Architecture and hands-on development of Enterprise Data Warehouse environment with focus on Data Integration (ETL) using any data Integration tool –  Talend, Pentaho  and Informatica · 2+ Years hands-on experience with Talend Big Data Integration version i.e. Design, develop ETL scripts, creating and deploying end to end Talend Data Big data Integration solution.   · Expert in ETL concepts of data integration, data migrations, data flow, data enrichment, data synchronization, change data capture and transformations.   · Expert level understanding of ETL frameworks – Developing Audit, Balance, Control; Validation architecture, Reconciliation etc. · Collaborate across multiple teams to research, architect, engineer and configure complex Data Integration solutions to specified requirements in support of global, business critical systems · Coordinate and oversee the assignments, delivery, and quality of deliverables. · Working experience with Hadoop ecosystem technologies (Hive, Pig, Spark), Distributed scalable data stores (HBase, Redshift), relational and NoSQL databases (Mongo DB, Cassandra etc ), Business intelligence tools and platforms/data quality tools would be advantage. · Working experience with Cloud Technologies AWS, Azure, Google cloud, Snowflake etc would be a big plus. · Experience in Agile. · Excellent communication, presentation & documentation skills. · Must be a team player with knowledge sharing capability."
83,6a5506f9aeee8c14444091f6d60616a5,https://www.mycareersfuture.sg/job/etl-sandbox-consulting-6a5506f9aeee8c14444091f6d60616a5,ETL,Permanent,SANDBOX CONSULTING PTE. LTD.,"TRIVEX, 8 BURN ROAD 369977","Senior Management, Middle Management",Information Technology,2000,7000,Monthly,18 Jan 2019,0,0,0,1,"QUALIFICATIONS: Required: ·         4+ years experience in information technology/computer science background ·         2+ years experience in a technical operations role (ITIL) ·         Working knowledge of Informatica 8.5, 9.6,10.2, Oracle Exadata, Cognos, Tableau and SAS. ·         Working knowledge on Bigdata environment is added advantage ·         Good Knowledge of Data Warehouse architecture, migration projects and Data Integration concepts. ·         Proficient in Microsoft Office products, MS Project, and Visio ·         Managing, organizing, and prioritizing multiple tasks and responsibilities. ·         Excellent communication skills, both verbal and written ·         Comfortable working with all project stakeholders (business users, architects, project managers, business analysts, developers, test analysts, production support team) ·         Telecom industry with CRM, Billing experience is strongly desired. ·         Amdocs/Kennan product knowledge is added advantage  ","QUALIFICATIONS: Required: ·         4+ years experience in information technology/computer science background ·         2+ years experience in a technical operations role (ITIL) ·         Working knowledge of Informatica 8.5, 9.6,10.2, Oracle Exadata, Cognos, Tableau and SAS. ·         Working knowledge on Bigdata environment is added advantage ·         Good Knowledge of Data Warehouse architecture, migration projects and Data Integration concepts. ·         Proficient in Microsoft Office products, MS Project, and Visio ·         Managing, organizing, and prioritizing multiple tasks and responsibilities. ·         Excellent communication skills, both verbal and written ·         Comfortable working with all project stakeholders (business users, architects, project managers, business analysts, developers, test analysts, production support team) ·         Telecom industry with CRM, Billing experience is strongly desired. ·         Amdocs/Kennan product knowledge is added advantage  "
84,a330651fbfd55e72e33da59c6fff3b38,https://www.mycareersfuture.sg/job/data-engineer-honestbee-a330651fbfd55e72e33da59c6fff3b38,Data Engineer,Permanent,HONESTBEE PTE. LTD.,"DELTA HOUSE, 2 ALEXANDRA ROAD 159919","Executive, Senior Executive",Information Technology,,,,18 Jan 2019,0,0,0,1,"As a Data Engineer at honestbee, you will be working alongside the brightest minds in the industry, solving some of the most challenging business problems using terabyte-scale of behavioural and transactional data. The solutions you create have a direct impact on millions of users in eight markets. What you'll be doing: - Be part of Asia’s strongest technology team in one of the world’s most exciting startups - Own, architect and scale honestbee’s bleeding-edge data platform  - Manage our data warehouse, OLAP, ETL systems, and data pipelines  - Contribute to further develop our best practices and innovation initiatives - Grow your skills and career in an environment that values continuous learning and personal development","Who you are: - Experienced in Python development - Proficient in SQL, Shell Scripting or another languages - Experience working with cloud-based and distributed systems (E.g. AWS ecosystem, Google Cloud, etc..) - Experience with building real-time stream-processing systems (E.g.Kafka, Fluentd, etc) - Knowledge of NoSQL databases (E.g.Redis, Elasticsearch, etc) - 2 to 5+ years of experience with data modelling and designing/supporting Data Warehouses (E.g. Redshift, BigQuery, etc) - 1 to 3+ years of experience in data processing/ETL implementation - Familiar with gunicorn, nginx, deployment and scalability (E.g. Kubernetes, Mesos, Marathon, etc)"
85,15ab556e0599771cd783db76b9bef5c0,https://www.mycareersfuture.sg/job/data-analytics-manager-sats-15ab556e0599771cd783db76b9bef5c0,Data Analytics Manager,Permanent,SATS LTD.,"SATS INFLIGHT CATERING CENTRE 1, 20 AIRPORT BOULEVARD 819659",Manager,Information Technology,,,,18 Jan 2019,0,0,0,1," Business Analytics   Build data visualisation and dashboard for the business and respective product owners Deliver accurate regular and ad-hoc performance tracking and analysis to drive traffic, transactions and processes Ad-hoc analysis based on strategic direction of the business and deep dive into specific area / trend Make recommendations based on historical data and predict trends Conduct market analysis leveraging on external data to determine market sizing and growth rates Assist in business case and pricing initiatives as required        2. Data Analytics  Design, develop and implement statistical models, as well as interpret and present statistical outcomes to support the organisation’s operations and execution of key business strategies Design and conceptualize solution that address the organisation’s challenges through use of big data analytics and process large amount of data by applying algorithms Collaborate with stakeholders to build data analytics capabilities, conduct feasibility studies, Knowledge of ETL and OLAP to support and contribute to database implementation and systems, devising strategies to promote continuous improvement Devise methods and strategies to obtain and extract data to derive business insights "," Degree holder in Business / Data Analytics, Business, Information Technology or Computer Science with at least 5 years of business analytics and/or data analytics Working knowledge of data mining principles: predictive analytics, mapping, collecting data from multiple data systems on premises and cloud-based data sources. Experience of Data Management Solutions and Data Warehouse Management. Understanding of and experience using analytical concepts and statistical techniques: hypothesis development, designing tests/experiments, analysing data, drawing conclusions, and developing actionable recommendations for business units. Experience and knowledge of analytical and statistical modelling techniques: hypothesis development, designing tests/experiments, analysing data, regression (multiple, logistic, log-linear), neural network, decision tree, variable selection, etc In-depth understanding of statistical and predictive analytics as well as text analytics implementation process Experience working with and creating databases and dashboards using all relevant data to inform decisions. Proficient with data analytics method and technologies / tools such as ETL, OLAP, R and/or Python and Qlik. Highly motivated, structured and methodical with high degree of initiative. Strong problem solving, quantitative and analytical abilities. Excellent written and oral communication skills. Able to work independently or cross functionally. "
86,abf461f251534f876db9a2d23175cb6e,https://www.mycareersfuture.sg/job/data-engineer-grabtaxi-holdings-abf461f251534f876db9a2d23175cb6e,Data Engineer,"Permanent, Full Time",GRABTAXI HOLDINGS PTE. LTD.,"OUE DOWNTOWN, 6 SHENTON WAY 068809",Professional,Information Technology,5300,8000,Monthly,18 Jan 2019,0,0,0,1," Build, deploy and manage big data solutions that can adequately handle the needs of a rapidly growing data driven company  Spearhead the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety)   Streamline data access and security to enable data scientists and analysts to easily access to data whenever they need to   Build out scalable and reliable ETL pipelines and processes to ingest data from a large number and variety of data sources   Maintain and optimize the performance of our data analytics infrastructure to ensure accurate, reliable and timely delivery of key insights for decision making     Lead the movement cleaning and normalizing subsets of data of interest as preparatory step before deeper analysis by the data scientists   Run Modern high performance analytical databases and computation engines like RedShift, BigQuery, Greenplum,Presto and others  ","  A degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines.   Experience in handling large data sets (multiple TBs) and working with structured, unstructured and geographical datasets   Designed high performance scalable infrastructure stacks for Big Data Analytics   Deep understanding of databases and best engineering practices - include handling and logging errors, monitoring the system, building human-fault-tolerant pipelines, understanding how to scale up, addressing continuous integration, knowledge of database administration, maintaining data cleaning and ensuring a deterministic pipeline   Real passion for data, new data technologies, and discovering new and interesting solutions to the company’s data needs   Excellent communication skills to communicate with the product development engineers to coordinate development of data pipelines, and or any new products features that can be built on top of the results of data analysis  "
87,c0f7f1cab964f2e5ac5f00720919ac0f,https://www.mycareersfuture.sg/job/business-intelligence-engineer-honestbee-c0f7f1cab964f2e5ac5f00720919ac0f,Business Intelligence Engineer,Full Time,HONESTBEE PTE. LTD.,"DELTA HOUSE, 2 ALEXANDRA ROAD 159919","Executive, Senior Executive",Information Technology,4500,6500,Monthly,18 Jan 2019,0,0,0,0,"What you will be doing: - Be part of Asia's strongest technology team in one of the world's most exciting startups - Manage and administer the BI platform (Looker) for the whole organisation - Manage the underlying data model, data warehousing, ETL processes and data pipelines for the BI platform - Collaborate with cross-functional stakeholders to understand the business needs, design and deliver end-to-end data solutions - Design dashboards to provide insights at scale and solve the analytical needs of the business user - Be a thought-leader who develops strategic and tactical data initiatives to drive data-driven operations and decisions, and self-service analytics throughout the organization - Grow your skills and career in an environment that values continuous learning and personal development","- You are a SQL ninja with proficiency in Python - You design dashboards that make data sing like Pavarotti - You have 2+ years of experience administering data analysis tools such as Looker, Tableau, QlikSense, PowerBI - You have 2+ years of experience with data modelling, data processing / ETL implementation, and supporting data warehouses (E.g. Redshift, BigQuery, etc) - You have demonstrated success in effective leadership, problem solving, prioritisation, and stakeholder management - You have strong communication (presentation, written, and listening) skills and excellent collaboration skills to work effectively with both engineers and business stakeholders - You enjoy working in a startup and are able to adapt to changing business needs - You are a quick learner with regards to both new businesses and technologies You are self-motivated and can work well under pressure"
88,0a5549a64db5a57016f6aac60f2a0d79,https://www.mycareersfuture.sg/job/software-consultant-0a5549a64db5a57016f6aac60f2a0d79,Software Consultant,"Contract, Full Time",Company Undisclosed,,Executive,Information Technology,6500,8500,Monthly,17 Jan 2019,1,0,0,0,"  ·          Very good understanding of Operational & Dimensional data model and providing recommendations, as appropriate  ·          Expert in devising ETL strategies  ·          Ability to take the requirements and convert into Design and disseminate the same to team  ·          Analyze requirements, perform impact analysis, design modules, build and unit test the code  ·          Hands on experience in writing complex Database queries, Procedures, Functions  ·          Excellent problem solving and analytical skills; including trouble shooting skills  ·          Excellent communications skills, both written and verbal  ·          Perform Unit Testing, SIT and necessary coordination  ·          Motivate team members & Inspire team to follow quality and processes","Experience in working with Informatica Power Center, Oracle PL/SQL (Stored Procedures, triggers, indexes), UNIX (shell scripts), DWH processes and concepts, performance tuning techniques, etc "
89,20ed0218069d90a20d10de004443b371,https://www.mycareersfuture.sg/job/senior-software-design-engineer-20ed0218069d90a20d10de004443b371,Senior Software Design Engineer,Full Time,Company Undisclosed,,Professional,Information Technology,5000,10000,Monthly,17 Jan 2019,0,0,0,0,"We are looking for 3 top-notch Software Engineers, who are well-versed in python, hand-crafting our high-performance data platform and AI engine, and fine-tuning our proprietary algorithms working side-by-side with our data scientists. Your primary focus will be the on-going development and the enhancement of our data infrastructure, ingesting and analyzing “big data” across myriad of data sources, including our frontend mApp. You also will be working closely with senior data scientists to deliver proprietary algorithms (algo packs) running at scale across our data platform sitting on top of Spark.  Writing modular, scalable and efficient code jointly developed with senior tech team on agreed architecture Implementation of security and data protection while ingesting and analyzing “big data” Real-time integration of various data sources, ingestion (ETL – extract, transform, and load) of data through our data pipes, and execution of algo packs delivering insights back to client’s systems Liaising with frontend developers/vendors to support the backend data platform Create and maintain software documentation "," Preferred Background in Computer Science, Computer Engineering or related disciplines although not necessary. Nontraditional acquisition of knowledge is not discriminated 1-4 years of relevant working experience, especially in large-scale production environment. Fresh graduates with strong Python skills are encouraged to apply. Excellent programming skill in one or more scripting languages: Python (must), Scala, Java, JavaScript. Understanding of the threading limitations of Python, and multi-process architecture. Background in machine learning is advantageous. Additional experience in Node JS and React Native would be great (but not necessary). Experience in any one of the following field is highly preferred: (i) cloud computing platform (ii) database management (NoSQL preferred) (iii) distributed computing/lambda architecture (iv) Spark and HDFS Prior startup or entrepreneurial experience would be a bonus. Can-do attitude "
90,8f859201827cc192dffeea3e4271b2b3,https://www.mycareersfuture.sg/job/data-platform-engineer-8f859201827cc192dffeea3e4271b2b3,Data Platform Engineer,Full Time,Company Undisclosed,,Senior Executive,Information Technology,4000,8000,Monthly,17 Jan 2019,0,0,0,0,"UCARE. AI'S team of data scientists and technologists came together with one mission: to use data ethically to solve real world problems and improve lives by creating the most advanced artifical intelligence capable of making accurate predictions years into the future. We are looking for 3 top-notch Python Hackers, who are well-versed in Python, hand-crafting our high performance data platform and AI engine (AlgoServer) and fine-tuning our proprietary algorithms (AlgoPacks) working side-by-side with our data scientists.  Your primary focus will be the on-going development and the enhancement of our data infrastructure, ingesting and analyzing ""big data"" across myriad of data sources, including our frontend mApp. You also will be working closely with senior data scientists to deliver proprietary algorithms running at scale across our data platform sitting on top of Spark. Duties and responsibilities:  Writing modular, scalable and efficient code jointly developed with senior tech team on agreed architecture. Implementation of security and data protection while ingesting and analyzing ""big data"" Real-time integration of various data sources, ingestion (ETL- extract, transform and load) of data through our data pipes, and execution of algo packs delivering insights back to client's systems. Liaising with frontend developers/vendors to support the backend data platform. Create and maintain software documentation. "," Preferred background in Computer Science, Computer Engineering or related disciplines. 1-4 years of relevant working experience, especially in large-scale production environment.  Fresh graduates with strong Python skills are encouraged to apply. Excellent prgramming skill in one or more scripting languages.  Python (must), Scala, Java, JavaScript. Understanding of the threading limitations of Python. and multi-process architecture. Background in machine learning is advantageous.  Additional experience in Node JS and React Native would be great (but not necessary). Experience in any one of the following field is highly preferred: (i)cloud computing platform (ii) database management (No SQL preferred) (iii) distributed computing/lambda architecture (iv) Sparks and HDFS Prior startup or entrepreneurial experience would be a bonus Can-do attitude "
91,848e577bdf80e2c8505e47611363c5e1,https://www.mycareersfuture.sg/job/informatica-cloud-developer-alphatech-business-solutions-848e577bdf80e2c8505e47611363c5e1,Informatica Cloud Developer,Contract,ALPHATECH BUSINESS SOLUTIONS PTE. LTD.,,Professional,Information Technology,7000,9000,Monthly,16 Jan 2019,1,0,0,0,"As a ETL developer, you will help to designs data storage systems, overseeing the loading of data into the systems and extract, transform, load (ETL) data with an emphasis to produce high quality software designs. What You Get To Do In This Role  Gathering requirements and specifications from users / business stake holders. Design, Develop and Test ETL Mappings, Mapplets, Workflows, Worklets to support business requirements. Perform feasibility, impact analysis and suitable solutions based on the use cases. Ensuring data management and governance to maintain the data integrity. Develop data mappings to extract the data from XML/Database and loading to the source stating database tables. Create shell scripts for ETL purpose. "," Degree in Computer Science/IT or equivalent. Relevant working experience in ETL, Informatica PowerCenter, SQL, PowerShell scripting, Databases, Unix Shell etc. Knowledge in the Data Warehousing Domain. Good understanding of RDBMS databases. Good exposure to different Data Modelling techniques. Familiar with Waterfall & Agile methodologies. Understand different interface files. Strong written and communication skills.   Experience working in Informatica ETL platform, Informatica Cloud hands on. Experience on IICS (Informatica Intelligent Cloud Services) of platform, hands on preferred. Experience working with Salesforce platform and knowledge of APIs (REST/SOAP/Bulk etc.) and usage with ICS (Informatica Cloud Services). Experience with Agile or Scrum development methodologies. Experience working in a cloud project delivery model, cloud automation solutions. "
92,539dc8331e61719ae515501579d2b20f,https://www.mycareersfuture.sg/job/gis-consultant-government-technology-agency-539dc8331e61719ae515501579d2b20f,GIS Consultant (Geospatial Specialist),Full Time,GOVERNMENT TECHNOLOGY AGENCY,"MAPLETREE BUSINESS CITY, 10 PASIR PANJANG ROAD 117438",Middle Management,"Information Technology, Public / Civil Service",5000,8000,Monthly,16 Jan 2019,0,0,0,0," We are seeking an experienced GIS Consultant to join our Geospatial Specialist Office (GSO), which aims at spurring innovative geospatial systems and solutions for Whole-of-Government (WoG).    As a GIS Consultant, you will collaborate with a team of talented GIS architects and consultants who are passionate about emerging technologies, and the use of geographic information systems (GIS) to drive WoG geospatial projects. You are a good communicator, capable of providing geospatial expertise and GIS product knowledge to conceptualize, architect, design and implement geospatial projects for government agencies.   What to Expect:     Provide Geospatial IT Consulting Services to government agencies, including:  Geospatial Planning & Strategy – Perform geospatial visioning and strategic planning, business case development, implementation planning, organisational planning, budgeting and risk management planning Detailed Requirement Gathering – Perform business process analysis, requirements analysis and use case analysis Architecture & Design – Develop geospatial data models and database design, system architecture design and application design Develop functional specs, tender documents, assist in calling, evaluating and awarding outsourced geospatial tenders Apps/System Development – Manage database development, application development, systems/Enterprise integration, quality assurance testing and configuration management Apps/System Deployment – Manage deployment planning, system installation, acceptance testing, performance validation, testing and tuning, User Training   Perform rapid prototyping and develop geospatial models, scripts and workbenches, ensuring reusability of codes, workbenches, ETL processes and other project artefacts Gain expertise in emerging geospatial related technologies such as 3D City Modelling, Indoor/Outdoor Positioning, AR, VR etc. Develop real-time geo-analytical models by integrating filed apps, sensors and IoT devices etc. Leverage existing central geospatial platforms and services to provide value added services and geo-enabled apps for government Assist in developing geospatial IT competency Assist in promoting use of geospatial IT within government, public and private sector  How to Succeed:   Disciplines in Geospatial Technology/Science, Computer Science/Engineering, Information Technology or equivalent Minimum 6 years of relevant GIS experience in solution design, IT consulting and/or project management Passionate about Geospatial technologies and allied emerging technologies ",None
93,4eba3a6d7a69b2994cb2b682b0bfb495,https://www.mycareersfuture.sg/job/informatica-power-center-developer-singapore-airlines-4eba3a6d7a69b2994cb2b682b0bfb495,Informatica - Power Center Developer,Permanent,SINGAPORE AIRLINES LIMITED,"AIRLINE HOUSE, 25 AIRLINE ROAD 819829","Professional, Executive",Information Technology,4500,9000,Monthly,16 Jan 2019,0,0,0,1," Design and develop new, complex ETL processes using Informatica Powercenter 9.x, complex event processing rules using Informatica Rule Point as well as web services / architecture supporting high transactional volumes. Involve in coding, testing, implementation, debugging, documentation and support. Gather and refine specifications and requirements based on technical needs. Records all specifications that are involved in the development and coding process. Work with other data analysts, business users and IT professionals to ensure that data requirements are met with the highest degree of integrity and efficiency. Involve in creating proper technical documentation in the work assignments. Ensure accurate software documentation, including detailed technical design, low level design and test scripts. Write automated unit, feature and regression test suites. "," Possess a degree in Information Technology or related fields. At least 3-5 years of development experience in ETL workflow process, Sessions, Data Mappings etc., being familiar with various software development practices (Eg: Agile software development methodologies). Experience working with Informatica Powercenter, Informatica Data Replication (IDR), Middleware platforms, JBoss, Weblogic or Websphere, Web applications, Middleware Technologies (MQ, TIBCO, JMS), and programming languages such as JSON, XML, Java and related technologies. Experience working with MPP Databases, preferably Greenplum. Experience with Airline or travel domain is preferred. Strong Database technical knowledge in the areas of general SQL and PL/SQL Should have quick learning ability and adapt to new technologies. Excellent analytical and problem solving skills and able to handle pressure situations without compromising on quality. "
94,4c723c701aee6e94e070cacf9a0d43bc,https://www.mycareersfuture.sg/job/etl-developer-4c723c701aee6e94e070cacf9a0d43bc,ETL Developer,"Permanent, Contract",Company Undisclosed,,Senior Executive,Information Technology,6000,8000,Monthly,16 Jan 2019,1,0,0,1,"Role is twofold depending on the chosen data architecture: Traditional BI & Analytics. Implement Extract, Transform & Load processes including data validation gates. Big Data / Data Lake, On top of ‘traditional activities’, also provide data wrangling setups to prepare the subset of datalake’s data for various business use cases","Engineer or University degree 5+ years of experience with ETL tools (Datasage, MS SSIS,…) Knowledge of data wrangling tools (trifacta, alteryx…)"
95,0ef5d18a9dd6e652d0ffe3b8cd07851b,https://www.mycareersfuture.sg/job/senior-software-developer-charterhouse-0ef5d18a9dd6e652d0ffe3b8cd07851b,Senior Software Developer,Contract,CHARTERHOUSE PTE. LTD.,"BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908",Executive,Information Technology,6000,8500,Monthly,15 Jan 2019,1,0,0,0," Perform design data model and develop extraction, loading and transformation ETL rules based on requirement Create technical design specification Fine tuning, and optimization of DB & ETL jobs Involve in System Integration test, User acceptance Test, Deployment and warranty support after implementation Ensure data quality throughout the ETL process Lead a team of developers "," Minimum 5 years of experience in Informatica, Teradata and UNIX Experience in ETL tools Hand on Experience on writing Teradata SQL. Should be expert in Teradata Utilities Should be good in Unix Shell scripting Experience in best practice of designing and developing of database, SQL, ETL process, logging, auditing, and error handling Good exposures and experience in Data Profiling and Data Modeling Experience in RDBMS  like Oracle, MS SQL etc Experience in creating test plan, test cases, test scripts and data integration. Experience in scripting Experience in following SDLC / Agile software development methodologies. Experience in banking industry  Please send your resume in word format with your current and expected salary to yvonnet@charterhouse.com.sg EA License no.: 13C6338 I Reg no.: R1110355"
96,4a7face004542ddc56cc8ace5ced9955,https://www.mycareersfuture.sg/job/software-engineer-encora-technologies-4a7face004542ddc56cc8ace5ced9955,Software Engineer,Contract,ENCORA TECHNOLOGIES PTE. LTD.,"THE SIGNATURE, 51 CHANGI BUSINESS PARK CENTRAL 2 486066",Middle Management,Information Technology,5000,7500,Monthly,15 Jan 2019,1,0,0,0,"3-6 months renewable contract through Encora  ·       Design, implement and support an analytical data infrastructure providing ad-hoc access to large datasets and computing power. ·       Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies. ·       Creation and support of real-time data pipelines built on AWS technologies including EMR, Glue, Kinesis, Redshift/Spectrum and Athena ·       Supporting existing ETL/ELT infrastructure built on Pentaho, Python, EMR ·       Continual research of the latest big data, elasticsearch technologies to provide new capabilities and increase efficiency ·       Working closely with team members to drive real-time model implementations for monitoring and alerting of systems. ·       Collaborate with other tech teams to implement advanced analytics algorithms that exploit our rich datasets for statistical analysis, prediction, clustering and machine learning ·       Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers","·       + years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets ·       Demonstrated strength in data modeling, ETL development, and data warehousing ·       Experience in programming in Python ·       Experience using big data technologies (think Hadoop, Hive, Hbase, Spark etc.) ·       Experience using business intelligence reporting tools (Tableau, Cognos etc.) ·       Knowledge of data management fundamentals and data storage principles Knowledge of distributed systems as it pertains to data storage and computing"
97,b6cd750d78ac8eb52fe762130f97b186,https://www.mycareersfuture.sg/job/data-engineer-rakuten-asia-b6cd750d78ac8eb52fe762130f97b186,Data Engineer,Full Time,RAKUTEN ASIA PTE. LTD.,"CAPITAGREEN, 138 MARKET STREET 048946",Manager,Information Technology,4500,8000,Monthly,15 Jan 2019,0,0,0,0," Implement cutting-edge data infrastructure platform which is vendor unlocked and multi-tenant. Implement and manage robust ETL pipeline based on streaming. Implement easy-to-use generalized data accessing layer by leveraging the details of storage engine. Implement distributed machine learning pipeline by coordinating with data science team. Develop data driven culture for integrated partners. Propose new technologies, tools to improve whole process of data system integration. ","Must have  Bachelor degree or higher in Computer Science or related field. Experience in at least one language for web backend application & data processing, such as Java, Python, etc. Experience in NoSQL database, such as Redis, Solr, MongoDB, etc. Experience in Linux system operation, ability to manage system level task such as monitoring and troubleshooting your deployed applications. Good communication skills, ability to work in fast pace R&D. High motivation for learning, skill up, system ownership and contribution to the team.  Must have for Senior position  3+ years of experience in developing large scale data processing platform of various unstructured data. 3+ years of experience in using various big data frameworks and NoSQL databases, such as Hadoop, Kafka, Redis, Solr, etc. Practical knowledge of web system performance tuning including OS, middleware, I/O and application.  Good to have  Experience on cloud computing service, such as AWS. Experience in handling multilingual data. Knowledge in data science domains, such as NLP, Data Mining, and Deep Learning will help your collaboration with the data scientists. "
98,f6e12e874137d15736ac219d5003d9af,https://www.mycareersfuture.sg/job/data-migration-senior-developer-f6e12e874137d15736ac219d5003d9af,Data Migration Senior  /  Developer (Ref 22827),"Contract, Full Time",Company Undisclosed,,Executive,Information Technology,4000,8000,Monthly,15 Jan 2019,1,0,0,0,"- Design, build and configure applications to meet business process and application requirements as part of Data Migration.  - Candidate should preferably be familiar with Data Modelling/ETL tools (Oracle Data integrator), XML and PL/SQL.","- Diploma / Degree holder with 3 - 8 years of working experiences - Experienced with Oracle Data Integrator (ODI), Oracle PL SQL                                Licence No: 12C6060"
99,13955977baf84da6704bce0d41447d7e,https://www.mycareersfuture.sg/job/data-migration-senior-developer-13955977baf84da6704bce0d41447d7e,Data Migration Senior  /  Developer  (Ref 22827),"Contract, Full Time",Company Undisclosed,,Executive,Information Technology,3000,6000,Monthly,15 Jan 2019,1,0,0,0,"- Design, build and configure applications to meet business process and application requirements as part of Data Migration.  - Candidate should preferably be familiar with Data Modelling/ETL tools (Oracle Data integrator), XML and PL/SQL.","- Diploma / Degree holder with 3 - 8 years of working experiences - Experienced with Oracle Data Integrator (ODI), Oracle PL SQL Licence No: 12C6060"
100,a3007b66c169e5aedc054113db367b06,https://www.mycareersfuture.sg/job/assistant-manager-manager-asset-liability-management-cimb-bank-berhad-a3007b66c169e5aedc054113db367b06,"Assistant Manager /  Manager, Asset Liability Management",Permanent,CIMB BANK BERHAD,"SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623",Manager,Banking and Finance,5500,8250,Monthly,14 Jan 2019,0,0,0,1,"Assistant Manager/ Manager, Asset Liability Management Responsibilities: -  Support BAU daily operations in ALM system (Liquidity/LCR/NSFR), to meet internal service level agreement and group regulatory reporting requirements.   Identify reporting issue, provide immediate investigation, raise incident log and work closely with local and Group IT and vendor for resolution.   Problem Log management and conduct daily/weekly status update.   Maintain and change the data mapping of ETL tool based on business requirement.   Maintain and configure Basel III LCR / NSFR business rules in ALM system. Provide 1st level of UAT support, including test progress update to internal stakeholders. Support ALM Data Analytics requirements and data preparation for ALM reporting & Dashboard.    Maintain and update ALM BI Dashboard based on business requirement.   ","Requirements:-  Bachelor Degree in Computer Science/ Information Systems/ Actuarial Science   3-4 years hands on experience in risk management systems, either in financial institutions or vendors.   Experience in IT infrastructure development including database, SQL server, DB scripts and dealing with ETL of large transaction volume is preferred.   Good understanding of financial products (Banking and Trading book).   Strong problem solving, critical thinking, written and verbal communication skills   Teamplayer who can work efficiently and multi-task   Experience in Dashboard building using BI tool (Qlik or Tableau) will be an advantage.   Knowledge of modern data science (e.g. SQL, R, Python, etc.) and concepts (e.g CAATs, trend analysis, data visualisation, data lineage, Hadoop, Spark etc ) will be an added advantage      Please send detailed resume, including salary expectation and contact number to: sg.enquiries@cimb.com  We regret only shortlisted candidates will be notified."
101,abee2fa5297a677c52ebf9cadfd78d1a,https://www.mycareersfuture.sg/job/senior-manager-data-architecture-abee2fa5297a677c52ebf9cadfd78d1a,"Senior  /  Manager, Data Architecture",Permanent,Company Undisclosed,"NTUC INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Manager,Information Technology,8000,15000,Monthly,14 Jan 2019,0,0,0,1,"You will be the Data Architect in NTUC Income and will create the strategic architecture roadmap for making digital experience a reality for our clients with modern data technologies. You are comfortable engaging senior stakeholders from both technology and business, and credibly guiding them to meet evolving market trends. You have deep and hands-on experience designing, developing high performance and scalable analytical solutions. You have a track record of implementing data and information architectures. You naturally collaborate with strategists and creative teams to workshop ideas, requirements, and define customer-centric experiences. You are passionate to deliver business value from data science, with an acute sense of change opportunities achievable with streaming analytics. You have overseen data management teams, working closely with application and technology teams.  Primary Responsibilities  Development of data architecture, strategy and governance to support business, application, security and technology strategic analysis and decision making   Assessment of current and target states of the data architecture to align with strategic or tactical objectives and to develop recommendations to close the gaps   Integrate cloud and on premise data warehouses and data lakes with metadata management, for powerful data-driven solutions   Be a trusted architect adviser to the management team and also give direction to guide the teams in solution design and implementation, being knowledgeable of data analytics trends   Presents roadmaps and architecture landscapes to senior stakeholders to fulfill the organization’s data science, cognitive, analytics and reporting requirements   Evaluation of data related technologies, and defining best practices in the assessments of standards, tools and methodologies including ETL development, to perform hands on data analysis   Create innovations in both analytic algorithms and methodologies with business impact. Responsible for the end-to-end process of analytical solutioning, involving conceptualization and business engagement   Ensures data quality and performs data cleansing to ensure a single source of truth, to enable data as a service for business units and front-end applications to consume   Perform quality review of data modeling design and deliverable, leading work sessions and deliverable presentations with business stakeholders   Manage architecture and technology governance committee agenda to ensure data, security and technology requirements aligned to enterprise standards and policies "," Bachelors or Master’s Degree in Computer Science, Information Technology, or equivalent   Minimum of 10 years IT experience and 5 years in data architecture, strategy, modeling and tools   At least 5 years design & development experience in enterprise data warehousing and analytics projects   Expert in Oracle, MSSQL, MYSQL database technologies   Best practices using data solutions using Hadoop, Cloudera, Spark, Kafka, MongoDB, NoSQL, Cassandra, Graph, etc   Familiar with Tableau, Microstrategy, Qlikview, Informatica, Talend, Hive and HBase   Understands machine learning, statistics, natural language processing, sentiment analysis, graph analysis, augmented and virtual reality   Proficient in handling complex technical development concepts, latest software tools and technologies, strong database concepts and designing techniques    Excellent in working effectively in a multi-tasking environment, ability to prioritize competing tasks   Fluency and efficiency in creating technical architecture documentation, presentations and stakeholder pitches   TOGAF or other industry recognized architecture certifications preferred   Competencies  Clear communicator with excellent oral and written skills and experience interacting with both business and IM individuals at all levels including the executive level    Possess the personal attributes of integrity, trust and credibility, hungry for results and show perseverance. A good listener, customer oriented, strong interpersonal skills   Creative thinking skills with deep technological expertise, business acumen and software development background   Able to guide and influence others easily and well organized with clear attention to detail   "
102,bce58906807f906dad5d70454e1d1e62,https://www.mycareersfuture.sg/job/software-consultant-bce58906807f906dad5d70454e1d1e62,Software Consultant,"Contract, Full Time",Company Undisclosed,,Senior Executive,Information Technology,6000,7500,Monthly,14 Jan 2019,1,0,0,0,"5+ years of experience in the IT industry with experience in migration preferably in OSS/BSS domain. •    Must have lead developer teams in a project, allocating work and following up to closure. •    Should have extensively worked on migration projects, Understanding of relational data models on ORACLE / MS SQL server databases. •    Hands on involvement in Low Level Design, Development and architecting of large Data migration projects leading developer and testing teams. •    Should possess Problem solving, Team building and Leadership Skills in a fast-paced, high-growth environment. •    Strong knowledge of Oracle and PLSQL programming. •    Knowledge of any of the ETL tools (ODI, Informatica) is desirable. •    Experience and ability to understand and interpret data migration strategies is desirable. •    Should have good problem solving skills and analytical skills serving as a bridge between the architect and execution team •    Ability to think through a problem and visualize the solution. •    An open mind towards new challenges. •    Exercise responsibility for architecture, design and documentation, adherence to software development life cycle guidelines, software version control standards and code promotion. •    Exposure to Media & Entertainment, Telecom will be an added advantage.",5+ years of experience in the IT industry with experience in migration preferably in OSS/BSS domain.
103,83fd52b4231f9df22e1f7bb3052964fb,https://www.mycareersfuture.sg/job/senior-software-developer-apar-innosys-83fd52b4231f9df22e1f7bb3052964fb,Senior Software Developer,Contract,APAR INNOSYS PTE. LTD.,"SGX CENTRE II, 4 SHENTON WAY 068807",Executive,Information Technology,6000,8500,Monthly,11 Jan 2019,1,0,0,0," Perform design data model and develop extraction, loading and transformation ETL rules based on requirement Create technical design specification Fine tuning, and optimization of DB & ETL jobs Involve in System Integration test, User acceptance Test, Deployment and warranty support after implementation Ensure data quality throughout the ETL process Lead a team of developers "," Minimum 5 years of experience in Informatica, Teradata and UNIX Experience in ETL tools Hand on Experience on writing Teradata SQL. Should be expert in Teradata Utilities Should be good in Unix Shell scripting Experience in best practice of designing and developing of database, SQL, ETL process, logging, auditing, and error handling Good exposures and experience in Data Profiling and Data Modeling Experience in RDBMS  like Oracle, MS SQL etc Experience in creating test plan, test cases, test scripts and data integration. Experience in scripting Experience in following SDLC / Agile software development methodologies. Experience in banking industry "
104,f2051b88516ce9d7f9297ea32965a1fd,https://www.mycareersfuture.sg/job/informatica-developer-addstones-sas-f2051b88516ce9d7f9297ea32965a1fd,Informatica Developer,Permanent,ADDSTONES SAS,,Manager,"Consulting , Banking and Finance, Information Technology",5000,9000,Monthly,11 Jan 2019,0,0,0,1,"GFI Group is an international business and technology solutions provider, currently employing about 18,000 people Worldwide. GFI provides its clients with long-lasting innovative solutions to leverage performance from their information systems. We design and run industrial platforms tailored to the economic and human considerations of our clients.  • Management Consulting | Digital Transformation | Innovation • Operating over 20 countries, • 2017 revenue of over 1,2 billion USD,  • 48 years of existence. In order to support our forthcoming businesses and technological challenges, we seek innovative and agile people sharing our mind set. We are now looking for an Informatica Developer to join our team in Singapore.   Role and responsibilities:   This role requires a strong, technical, hands-on person focusing on Informatica infrastructure. The successful candidate will be a member of a dynamic IT Architecture team and will work with other Singapore, Hong-Kong and regional IT teams.  The Informatica Developer will be:   ·         Working with Business team to understand the requirements. ·         Managing and supporting Informatica in Linux environment. ·         Designing and developing complex Informatica ETL processes that integrate large data sets from multiple sources ·         Loading data warehouse objects including dimensions, hierarchies, fact tables and aggregates ·         Ability to create the metadata layers including physical, semantic and presentation layers ·         Experience with Oracle Data Warehouse Console (DAC) ·         Loading data into an enterprise data warehouse environment ·         Developing and maintaining Informatica PowerCenter solutions ·         Performing systems and data analysis to implement and optimize Informatica mappings and ETL workflows, data flows, shell scripts and stored procedure ·         Ensuring accuracy and integrity of data and applications through analysis, coding, writing clear documentation and problem resolution ·         ETL support experience: monitor, troubleshoot, track and document day-to-day production issues  ","Qualifications and Profile:   ·         At least 5 years of experience of Informatica development. ·         Experience in setting up ETL using Oracle EBS as the datasource ·         Experience working with a job scheduler application (Autosys) to design and schedule Informatica workflow ·         Experience with RDBMS (Oracle/SQL Server etc) and writing and tuning Oracle SQL and PL/SQL statements ·         Takes initiative and is results driven ·         Strong decision making and analytical skills ·         Act with integrity ·         Ability to manage change and complexity with confidence ·         Strong team player ·         Client focused and commercial thinking ·         Excellent interpersonal and communication skills ·         Self-motivated and genuine interest in Banking and Finance ·         Proficiency in Microsoft office (MS Word, Excel & Power point) ·         Exposure to big data and programming is a plus    "
105,22b99c14c5682996d485aad953c2ecd7,https://www.mycareersfuture.sg/job/senior-datawarehouse-consultant-apar-innosys-22b99c14c5682996d485aad953c2ecd7,Senior Datawarehouse Consultant,Contract,APAR INNOSYS PTE. LTD.,"SGX CENTRE II, 4 SHENTON WAY 068807",Executive,Information Technology,6000,8000,Monthly,11 Jan 2019,1,0,0,0," Prepare Test cases for pre-UAT, wherever applicable. Represent user for pre-UAT. Validate test results and perform functional testing. Co-ordinate UAT phase with business users and Vendor Data Analysts. Responsible for obtaining UAT sign-off from user. Responsible for conducting user training on Business intelligence platform access layers / Reports.  Experience in SDLC of Datawarehouse Projects from Business Requirements gathering, Data profiling, Data modelling & Mapping, ETL coding and reports creation. Creation of Conceptual, Logical and Physical data models for OLTP and OLAP systems Practice range of options for common ETL design and techniques in data cleansing and optimization for extracting, transforming, cleansing and loading data from various relational and non-relational data sources systems. "," Degree in Statistics, Mathematics, Computer Sciences, or equivalent studies with at least 4 years of data analyst experience in the technological field Sound knowledge of financial service logical data model (Teradata FSLDM). 4 to 6 years of related work experience required. Technical expertise regarding data warehouses is must. Understanding of relational databases; including SQL required. Should have extensive experience in Teradata, ETL, Unix Banking domain experience is a must Should have lead mid to large size team Excellent communication & interpersonal skills Must have experience effectively using communication skills to achieve mutual understanding. "
106,f0e491ef2e9fc6d0181670bbd0a33a3e,https://www.mycareersfuture.sg/job/assistant-manager-samsung-sds-asia-pacific-f0e491ef2e9fc6d0181670bbd0a33a3e,Assistant Manager,Permanent,SAMSUNG SDS ASIA PACIFIC PTE. LTD.,"MAPLETREE BUSINESS CITY, 30 PASIR PANJANG ROAD 117440","Professional, Senior Executive",Information Technology,3500,7000,Monthly,11 Jan 2019,0,0,0,1," Compile complex data sets from a variety of sources Implement data models through creation and maintenance data in the choice of database server and/or other data storage platform Create sustainable and efficient BI dashboard visualizations, emphasizing usability and good design practices Testing and monitoring the underlying data, ensuring quality and optimizing the data view that dashboards use Work with the business support team to automate the ETL tasks Identify software, tools, and techniques that have potential to advance the state of Business Intelligence across the company "," Bachelor's degree in Mathematics, Computer Science or Engineering, preferably in a quantitative field. Experience with Data Visualization (Tableau required and other reporting/BI tools) 3 to 5 years of with extensive experience in BI Dashboard and ETL development. Strong knowledge in data architecture, ETL, data warehouse, database technology (SQL Server, DB2, etc.) Prior Experience in developing and performing complex SQL queries or similar relational database/dimensional language Proficient in MS Excel, including pivot tables, look up functions and charts Knowledge in Java Spring MVC, R, Python, or related programming language is a plus Experience with on premise and/or cloud architecture and deployment Capable of seeking information, solving conceptual problems, corralling resources, and delivering results in challenging situations Self-motivated and able to work in a fast-paced, ever-changing environment Good time management and ability to prioritize tasks and work within deadlines Able to work independently with minimum supervision "
107,189dd8637b4193915e4a37247baa461c,https://www.mycareersfuture.sg/job/data-engineer-grabtaxi-holdings-189dd8637b4193915e4a37247baa461c,Data Engineer,Full Time,GRABTAXI HOLDINGS PTE. LTD.,"OUE DOWNTOWN, 6 SHENTON WAY 068809",Professional,Engineering,6000,10000,Monthly,11 Jan 2019,0,0,0,0," Build, deploy and manage big data solutions that can adequately handle the needs of a rapidly growing data driven company  Spearhead the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety)   Streamline data access and security to enable data scientists and analysts to easily access to data whenever they need to   Build out scalable and reliable ETL pipelines and processes to ingest data from a large number and variety of data sources   Maintain and optimize the performance of our data analytics infrastructure to ensure accurate, reliable and timely delivery of key insights for decision making     Lead the movement cleaning and normalizing subsets of data of interest as preparatory step before deeper analysis by the data scientists   Run Modern high performance analytical databases and computation engines like RedShift, BigQuery, Greenplum,Presto and others  ","  A degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines.   Experience in handling large data sets (multiple TBs) and working with structured, unstructured and geographical datasets   Designed high performance scalable infrastructure stacks for Big Data Analytics   Deep understanding of databases and best engineering practices - include handling and logging errors, monitoring the system, building human-fault-tolerant pipelines, understanding how to scale up, addressing continuous integration, knowledge of database administration, maintaining data cleaning and ensuring a deterministic pipeline   Real passion for data, new data technologies, and discovering new and interesting solutions to the company’s data needs   Excellent communication skills to communicate with the product development engineers to coordinate development of data pipelines, and or any new products features that can be built on top of the results of data analysis  "
108,e4c6f8589f88e909930de502e26deaa1,https://www.mycareersfuture.sg/job/senior-datawarehouse-consultant-apar-technologies-e4c6f8589f88e909930de502e26deaa1,Senior Datawarehouse Consultant,Contract,APAR TECHNOLOGIES PTE. LTD.,"SGX CENTRE II, 4 SHENTON WAY 068807",Professional,Information Technology,6000,8000,Monthly,10 Jan 2019,1,0,0,0," Prepare Test cases for pre-UAT, wherever applicable. Represent user for pre-UAT. Validate test results and perform functional testing. Co-ordinate UAT phase with business users and Vendor Data Analysts. Responsible for obtaining UAT sign-off from user. Responsible for conducting user training on Business intelligence platform access layers / Reports.  Experience in SDLC of Datawarehouse Projects from Business Requirements gathering, Data profiling, Data modelling & Mapping, ETL coding and reports creation. Creation of Conceptual, Logical and Physical data models for OLTP and OLAP systems Practice range of options for common ETL design and techniques in data cleansing and optimization for extracting, transforming, cleansing and loading data from various relational and non-relational data sources systems. "," Degree in Statistics, Mathematics, Computer Sciences, or equivalent studies with at least 4 years of data analyst experience in the technological field Sound knowledge of financial service logical data model (Teradata FSLDM). 4 to 6 years of related work experience required. Technical expertise regarding data warehouses is must. Understanding of relational databases; including SQL required. Should have extensive experience in Teradata, ETL, Unix Banking domain experience is a must Should have lead mid to large size team Excellent communication & interpersonal skills Must have experience effectively using communication skills to achieve mutual understanding.  Qualified and interested candidate may send updated resume to julliete.parico@apar.com Registration ID – R1112163 EA License No – 11C4879"
109,49a177c846157e29852dac5925ef5e6c,https://www.mycareersfuture.sg/job/informatica-developer-itcan-49a177c846157e29852dac5925ef5e6c,Informatica Developer,Full Time,ITCAN PTE. LIMITED,"PRUDENTIAL TOWER, 30 CECIL STREET 049712","Professional, Executive",Information Technology,4000,7500,Monthly,10 Jan 2019,0,0,0,0," Design and develop solutions for Strategic DAL components Review requirements, prepare/contribute to design decisions & testing strategy Interface with architects, PM Act as a SME for Strategic  ETL/Oracle components Supporting functional testing as well as support Strong technical skills/experience within the CFO domain  "," Diploma or Degree with 3 years of experience in Informatica Development. Expertise is in Data Warehousing, ETL (Extract/Transform/Load), Data Analysis, Data Conversion/Transformation, Enterprise Data Warehouse Maintenance and Support Design, Develop and Test ETL Mappings, Mapplets, Workflows, Worklets using Informatica Powercenter 9.x & above Experience in SQL Server Database Exposure to Data Modelling techniques. Create UNIX shell scripts for ETL purpose. Understanding to concepts of SDLC methodologies like Waterfall & Agile is desirable. Banking knowledge is desirable. Work in a fast paced environment, under minimal supervision to perform as an Inpidual Contributor. Communicate clearly and concisely verbally and in writing. "
110,9e0b75cb0554ec9a9be64d1e8d55e8a0,https://www.mycareersfuture.sg/job/etl-developer-encora-technologies-9e0b75cb0554ec9a9be64d1e8d55e8a0,ETL(Informatica) Developer,Contract,ENCORA TECHNOLOGIES PTE. LTD.,"THE SIGNATURE, 51 CHANGI BUSINESS PARK CENTRAL 2 486066",Professional,Banking and Finance,6000,7500,Monthly,09 Jan 2019,1,0,0,0,"To support project as ETL Team Lead • Informatica , Unix shell, Oracle & PL/SQL","Possess 7-8years experience , preferably 3 years spent within Financial or Telco Industry • Managed/Supervised a small team of developers(under 5) and oversee daily activities to deliver solutions in support of Business • Familiarity with SDLC lifecycle as well as Agile/Scrum/Lean methodologies • Strong communication and collaboration skills, have experience working in big projects /programmes(concurrent multiple projects) with multiple stakeholders/customers as well supporting parties • Possess strong problem solving skills ,has keen eye for details ,quality consciousness and actively uses initiative to creatively resolve issues or improve internal processes"
111,2932601cd80992237465b77cd6bcf9a8,https://www.mycareersfuture.sg/job/business-intelligence-analyst-developer-d2x-expertise-2932601cd80992237465b77cd6bcf9a8,Business Intelligence Analyst Developer,"Permanent, Full Time",D2X EXPERTISE PTE. LTD.,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616",Professional,"Customer Service, Logistics / Supply Chain",4000,9000,Monthly,09 Jan 2019,0,0,0,1,"We are looking for a Business Intelligence (BI) Analyst / Developer to create and manage BI and analytics solutions that turn data into information supporting decision making. Responsibilities :  Gather, analyze, and document reporting requirements, develop by yourself (both static reports and interactive dashboards) Work closely with business stakeholders to make sure data definitions and technical logic specifications align with business requirements Perform data extractions via SQL and present findings to stakeholders Identify relevant data sources to feed data models, Source and Prepare data Document test plan, test cases, test scripts and perform QA activities Build/Improve automated workflows and data checks to provide smooth running, data integrity and accurate reporting, ensuring consistency of information across reports. Perform routine maintenance to ensure stability and performance of systems and data delivery on time Analyze production problems, realize/recommend data correction Support remote BI users on: best practices on BI tools, where to find data, troubleshooting Maintain user guides and release notes up to date Perform upgrade of the systems and applications to the new versions Work with vendors (IBM, Microsoft) on technical issues resolution Create/Update technical documentation for database/ETL/reports "," 5+ years of experience in business intelligence development Good oral and written English. Strong with full Cognos suite: Framework Manager, Report Studio, Analysis Studio, Dashboard... Strong with SQL (preferably T-SQL) Experience modeling and designing relational DBs, star schemas, and cubes Good knowledge of at least one of the functional areas: finance management, customer relationships and sales, freight forwarding or logistics operations Must be able to work collaboratively with cross-functional teams to analyze and understand business needs in order to translate them into system specifications and deliverable solutions. Self-starter with ability to work independently with minimal supervision and manage own workload. Proactive, able to suggest improvements of processes, systems, code... and prioritize them Must be willing to work with and learn new technologies Familiar with project management concepts (Waterfall and Agile).  Additional good to have qualification:           Experience\knowledge of finance (non-banking), transportation or logistics domains          Experience with \understanding of OLAP solutions and MDX (TM1 especially)          Experience with \understanding of predictive modeling (SPSS, R, Phyton)          Advanced Excel skills, including pivot tables and VBA    Skills  Examines complex data in a critical way; Synthesizes diverse information; Able to source and prepare data; Designs work  flows  and procedures. Applies design principles; Uses feedback to modify designs; Demonstrates attention to detail. Problem Solving: Identifies and resolves problems in a timely manner; Foresee and communicate potential issues; Develops alternative  solutions;  Works  well  in  group problem solving situations. :  Assesses own strengths  and  weaknesses;  Pursues  training  and development  opportunities; Shares expertise with others : Clear communication on requirements (listening and asking questions); Ability to engage and communicate effectively with stakeholders at all levels across the business Business Acumen: Understands business implications of data for decisions : Demonstrates accuracy and thoroughness; Looks for ways to improve and promote quality; Applies feedback to improve performance; Monitors own work to ensure quality "
112,1f257f3fe7b5eebd4832a6d4f3f9bfe6,https://www.mycareersfuture.sg/job/avp-data-engineer-ibg-digital-institutional-banking-group-dbs-bank-1f257f3fe7b5eebd4832a6d4f3f9bfe6,"AVP, Data Engineer, IBG Digital, Institutional Banking Group (1800044U)","Permanent, Full Time",DBS BANK LTD.,,"Manager, Senior Executive",Banking and Finance,6500,11700,Monthly,09 Jan 2019,0,0,0,1,"Job Purpose  The Data Engineer will provide big data engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be one excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities  Create and maintain optimal data pipeline architecture; Assemble large, complex data sets that meet functional / non-functional business requirements; Identify, design, and implement internal process improvements: automating manual processes, Perform ETL/ELT, Data Modelling, Data Profiling, Data Cleansing, Feature Engineering tasks as part of Data Analytics Life Cycle (DALC); Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs; Build processes supporting data transformation, data structures, dependency and workload management "," Master’s Degree in software Engineering, Computer Science or related fields with minimum 3 years data engineering work experience in big data analytics environment Strong in data engineering skills with big data stack (Hadoop, Spark, Kafka, etc) Strong in transactional SQL, Enterprise Data Warehouse Experience with Graph Database, NoSQL databases Experience with Feature Engineering Experience with Master Data Management Experience with scripting languages: UNIX/Linux Shell, SQL, Python (Pandas, PySpark etc), Scala, R, etc "
113,89827330ea0c49864b2a6ea27caa1932,https://www.mycareersfuture.sg/job/senior-associate-data-engineer-ibg-digital-institutional-banking-group-dbs-bank-89827330ea0c49864b2a6ea27caa1932,"Senior Associate, Data Engineer, IBG Digital, Institutional Banking Group (1800044U)","Permanent, Full Time",DBS BANK LTD.,,"Manager, Senior Executive",Banking and Finance,5000,9000,Monthly,09 Jan 2019,0,0,0,1,"Job Purpose  The Data Engineer will provide big data engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be one excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities  Create and maintain optimal data pipeline architecture; Assemble large, complex data sets that meet functional / non-functional business requirements; Identify, design, and implement internal process improvements: automating manual processes, Perform ETL/ELT, Data Modelling, Data Profiling, Data Cleansing, Feature Engineering tasks as part of Data Analytics Life Cycle (DALC); Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs; Build processes supporting data transformation, data structures, dependency and workload management "," Master’s Degree in software Engineering, Computer Science or related fields with minimum 3 years data engineering work experience in big data analytics environment Strong in data engineering skills with big data stack (Hadoop, Spark, Kafka, etc) Strong in transactional SQL, Enterprise Data Warehouse Experience with Graph Database, NoSQL databases Experience with Feature Engineering Experience with Master Data Management Experience with scripting languages: UNIX/Linux Shell, SQL, Python (Pandas, PySpark etc), Scala, R, etc "
114,169c28e1a425e08088a11467ce1290ba,https://www.mycareersfuture.sg/job/technical-consultant-169c28e1a425e08088a11467ce1290ba,Technical Consultant,"Permanent, Full Time",Company Undisclosed,,Professional,Information Technology,4000,5000,Monthly,09 Jan 2019,0,0,0,1,"• Provide knowledge of the functionality of one or more core NetReveal modules (such as ETL, Builder, Workbench,          Visualizer, Live, Scenario Manager, WLM, Services Manager and Application Builder) • Participate in the technical workshops during the analysis and design stages of project • Support technical delivery of aspects of the solution • Create the project environments mirroring the hardware and software stack to be used on client site • Configure technical aspects of the Netreveal product e.g. Scenario Manager, WLM, Workbench • Configure the Netreveal Application to meet client requirement • Trouble-shoot environmental & technical issues that arise in the course of deploying/configuring software • Deploy application releases onto the project environment and on client site when required • Assist in improvements to our software, processes or supporting documentation • Demonstrate good communication and interpersonal skills towards clients and internal project team • Demonstrate flexibility and ability to take the initiative on issues • Effective and Efficient decision making ability – prioritizing, time management, etc","• Typically 2-4 years experience or equivalent in a technical role such as programming, technical/IT support, software        installation. • Grows technical knowledge of new aspects of the NetReveal product, asking for guidance where appropriate and            rapidly picking up new skills. • Technical trouble shooting skills • Previous experience of installing software, creating test environments • Good knowledge of SQL and in-depth experience of databases such as Oracle, DB2, SQL Server or Teradata and          performance tuning at a database level • Some knowledge of application servers such as Websphere, Weblogic, Apache Tomcat, JBoss • Good knowledge of operating systems such as Unix Solaris, AIX, Linux, HPUX • Understanding of Java and J2EE architectures/and/or Data Server"
115,cb7271da6bec8cfefa49c74f9184a096,https://www.mycareersfuture.sg/job/data-engineer-machine-learning-engineer-oneconnect-financial-technology-cb7271da6bec8cfefa49c74f9184a096,Data Engineer / Machine Learning Engineer,Permanent,ONECONNECT FINANCIAL TECHNOLOGY (SINGAPORE) CO. PTE. LTD.,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616",Professional,Engineering,3000,4000,Monthly,08 Jan 2019,0,0,0,1,"As a data/Machine learning engineer, your primary goal is to work with data scientist and software developers to implement and deploy machine learning algorithms driven data solutions in commercial environment. You’ll work with data scientist to build specialized tools to facilitate data preprocessing, data quality check, data cleansing, ETL and data integration. You’ll work with backend and frontend app-dev team to implement high performance machine learning algorithms on commercial enterprise software platform. Key requirement:  Advanced degree in Computer Science, Electronic Engineering, Statistics, Applied Mathematics, or related technical fields. Minimum 2 years relevant experience. Proficiency in a high performance programming language such as Java/C++. Good working knowledge in a scripting language such as Python/R. Experience implementing algorithms in big data/cloud computing environment. Experience in solving real-world data challenges and dealing with anomalies. Good knowledge working with relational database and NoSQL database Good communication skills ","Preferred requirement:  Experience building labeled datasets from scratch, or developing tools protocol formalizing unstructured unlabeled data. Experience handling high-volume real-time data stream Experience building complete data pipeline, ingesting data from multiple source systems (potentially asynchronous and different rate) Experience building large scale parallel/distributed data processing, machine learning solutions Experience building robust and high-throughput API for analytics-as-a-service solutions Experience working with enterprise app engine technology such as cloud computing, container technology for high availability and robust deployment. "
116,b495b5797dee28b2ad624403e81945e6,https://www.mycareersfuture.sg/job/data-scientist-singapore-telecommunications-b495b5797dee28b2ad624403e81945e6,Data Scientist (Cyber Security),"Permanent, Full Time",SINGAPORE TELECOMMUNICATIONS LIMITED,"COMCENTRE, 31 EXETER ROAD 239732",Professional,Information Technology,6000,8000,Monthly,08 Jan 2019,0,0,0,1,"We are looking for a creative data scientist to join our project team that builds robust cyber security software and services. The candidate will be responsible for building and executing analytics modules:  Own and complete work streams for execution and delivery. Able to make presentations to internal and external stakeholders for own work Able to perform ETL, feature selections, modeling, model validation and conducting data analyses Self-motivated, independent learner, and enjoy sharing knowledge with team members "," Relevant degree in Computer Science, Computer Engineering, Mathematics, Statistics or a related field with exposure to Machine Learning and/or Advanced Analytics with 2+ years of experience in predictive analytics and exposure to big data analytics Experience in cyber security domain is a plus Strong coding skills in Python is a must Hands-on experience with Python libraries - NumPy, Pandas, sklearn Hands-on knowledge of working with scalable platforms such as Hive, Hadoop or Spark (PySpark) is a plus. Comfortable with working on Unix, Windows and both SQL and NoSQL databases Sound knowledge of machine learning concepts. "
117,9a2882ca74c6e52d5a8f33fbc7a5a572,https://www.mycareersfuture.sg/job/data-engineer-moka-technology-solutions-9a2882ca74c6e52d5a8f33fbc7a5a572,Data Engineer,"Permanent, Full Time",MOKA TECHNOLOGY SOLUTIONS PTE. LTD.,,Professional,Engineering,5000,7000,Monthly,08 Jan 2019,0,0,0,1,"Do you have a passion for data? Are you looking to push the frontiers of innovation and build the Next Big Data Product? We are looking for excellent Data Engineers who are keen to help us manage the end-to-end data pipeline and drive big data solutions.  You will:  Design, implement and manage end to end data pipelines (ETL, data streaming and warehousing) so as to make data easily accessible for analysis. Integrate with third party APIs for accessing external data. Create and maintain data warehouses for reporting or analysis. Consult and partner with engineering and product teams to execute data-related product initiatives. Ability to quickly resolve performance and systems incidents. Evaluate the latest monitoring and automation tools. ","You have:  BS (MS preferred) in Computer Science or Computer Engineering. Excellent software engineering skills and proven track record (4+ years experience) in building automated, scalable and robust data processing systems. Proficiency in SQL, bash scripts and Python (or similar languages). Intermediate understanding of database technologies. Experience with data warehouse systems (e.g. Redshift) and batch/semi-online building blocks (e.g. MapReduce, Spark etc). Demonstrated expertise in working with large scale quantitative data. Excellent attention to detail and team player. "
118,b1e875e5bdf56b69b285c64dccfc666c,https://www.mycareersfuture.sg/job/data-engineer-hooq-digital-b1e875e5bdf56b69b285c64dccfc666c,Data Engineer,Permanent,HOOQ DIGITAL PTE. LTD.,"COMCENTRE, 31 EXETER ROAD 239732",Manager,"Engineering, Information Technology",,,,07 Jan 2019,0,0,0,1,"We are looking for a Data Engineer to join our rapidly expanding Data & Analytics team. You will help shape how we build and grow our service in the region. We look for self-starters who demand the best. Key Responsibilities:   Develop ETL/ELT jobs to integrate new data into the data warehouse or build new reporting schemas   Develop data pipelines, both bath and realtime from various platforms into the data lake   Manage various data platforms and seek out new technologies to improve efficiency   Develop advanced analytical models that help the business identify trends within customer base and behavior   Work closely with the business to understand data needs and create data sets to enable reporting and dashboards to monitor business performance   Ensure the data warehouse load jobs run as per schedule and data availability to the business is uninterrupted   Continuously improve the information management platforms of the company to leverage benefits ","Desired Skills and Experience  Minimum 3 years of solid development experience within a data warehouse/information management team with strong understanding of programming languages like Java, Python, JavaScript and SQL.   Hands on experience in full-stack development, design and architecture. Experience in creating a REST API that can handle a production load (code + deploy).   Familiarity with AWS (DynamoDB, Redshift, S3, EC2, RDS, Lambda) (Will be an advantage but not mandatory)   Minimum 3 years development experience with ETL/ELT tools (preferably Pentaho DI, Informatica, Datastage or Talend)   Proven experience with Data Warehousing and Big Data technologies   Working knowledge of big Data Technologies like Hadoop, Hive, Spark and streaming/messaging services like Kafka,Spark streaming.   Solid understanding of some BI tools such as Cognos, QlikView or Tableau.   Comfortable working in dynamic fast paced environment with competing priorities. Self-starter and willing and able to learn on your own   Work well within a team environment and willing to accommodate task and duties that maybe outside of your JD for limited time periods "
119,2215e8a8684aaa50c17489883ae473b0,https://www.mycareersfuture.sg/job/data-engineer-fixed-mobile-2215e8a8684aaa50c17489883ae473b0,Data Engineer,Permanent,FIXED & MOBILE PTE. LTD.,"ANSON HOUSE, 72 ANSON ROAD 079911",Non-executive,Information Technology,4000,7000,Monthly,07 Jan 2019,0,0,0,1,"TransferTo operates a leading global digital value services network offering safe, reliable and more accessible mobile value services for emerging markets. Our B2B cross-border network interconnects and provides mobile operators, money transfer operators, retailers, distributors, NGOs and corporates with unparalleled infrastructure and reach to offer solutions that better connect loved ones across borders. A career with TransferTo provides invaluable experience in an exciting and rapidly expanding market and an opportunity to be part of a truly global company with 7 offices worldwide and a workforce that includes over 50 different nationalities. The Data Science & Data Engineering department is focusing on the creation of new data sciences capabilities for the business by envisioning and executing strategies that will improve performance by enabling informed decision making. We are seeking an energetic and passionate data engineer to help build the robust foundations that will support current and future data-intensive computations across the company. As a Data Engineer, you will be working closely with the Infrastructure, Software development, Business Intelligence and Data Science teams. You will have the opportunity to shape our data stack, ensuring that our ever-flowing data is adequately collected, organized and made accessible for advanced analytics and beyond. Key Role Responsibilities  Build a reliable, scalable and efficient cloud-based data processing platform and applications Play a central role in delivering our next generation real-time, big data platform Conceive, develop, monitor and optimize reliable data pipelines that convert data into insights Be involved in whole data platform development process including infra, data ETL and service implementation  About Us TransferTo operates a leading global digital value services network offering safe, reliable and more accessible mobile value services for emerging markets. Our B2B cross-border network interconnects and provides mobile operators, money transfer operators, retailers, distributors, NGOs and corporates with unparalleled infrastructure and reach to offer solutions that better connect loved ones across borders. For more information, visitwww.transfer-to.com/digitalvalue","Essential Experience  More than 3 years of experience in data engineering Advanced knowledge of real-time data streams, ETL processes and how to clean, structure and manage sensitive data effectively Strong development skills in some of the following languages: R, Python, Hive, Pig, Mahout, Java, ... Working knowledge of big data concepts like Hadoop, Spark, MapReduce, and HDFS Deep understanding of both SQL and NoSQL data stores Familiar with data tools and services in Azure, AWS, and/or GCP eco-system is preferred Familiar with data management and visualization tools such as Tableau Knowledge of Amazon AWS services and their applications (RDS, Redshift, S3, EC2, ...) Knowledge in RESTful API development Knowledge in CI tools like Jenkins Knowledge in QA processes and automation Coursework in machine learning, data science, data mining, big data, and/or statistical inference is a plus Comfortable with GIT version control Excellent written and verbal communication skills in English A DevOps attitude - you build it, run it & maintain it The ability to execute independently Enjoy learning and adopting new technologies to push the team forward Thrilled to find creative solutions for the challenges you face Finally, wanting to have responsibilities that make a significant contribution and impact on the company "
120,c356258fe234b2a5dcf2d4d15e2e2c3e,https://www.mycareersfuture.sg/job/senior-etl-developer-etiqa-insurance-c356258fe234b2a5dcf2d4d15e2e2c3e,Senior ETL Developer,"Permanent, Contract",ETIQA INSURANCE PTE. LTD.,1 RAFFLES QUAY 048583,Senior Executive,Information Technology,6000,8500,Monthly,04 Jan 2019,1,0,0,1,"Responsibilities  Develop ETL data workflows and code for new data integrations and maintain/enhance existing data flows and packages. Familiar with IBM AS400, File, SQL, Ole-DB, ODBC providers for connect to different system or applications make data exchange. Perform data analysis and propose and ensure transformation covers all data possibilities including managing data anomalies, and exception handling. Provide support to technical team, write the necessary required documentation as per the development methodology for ETL processes, and develop unit test plan, test cases and resolve ETL related test issues. Data modeling design, according to business requires for dimension design, functions calculation. Reporting service development, store procedure or T-SQL query data. Provide in-depth troubleshooting skills to assist in resolving errors and performance issues including production support. Keep alert of integrated product developments that translate to environmental or code modifications. Comply with internal development coding standards, procedural guides, and checklists for the support of the database systems. Interacting with individuals from across the company in different supporting organizations and business groups. Ability to research, learn, troubleshoot and support complex system customizations ","Requirements  At least Bachelor’s degree in Computer Science or technology related field. At least 5-6 years MS SQL Server experiences, design data modelling and solutions to fulfil business and system data requirements. T-SQL development experience in SQL Server 2008 - 2016 databases, writing complex SQL (stored procedures, functions, views), Familiar SQL Server, DB2/AS400, script the Store procedure. 3 years of experience in SSIS Package Maintenance and Development, familiar with control flow and data flow development. Define, develop and sustain the database physical structure and functional capabilities, database security, data back-up, and recovery specifications Turning database performance, calculating values for database parameters to provide fast responses to end users. Support database functions by designing and coding utilities. Skillful of SQL Server development and database structures, report development with SSRS. "
121,c7f5471cce4ad3ee2be6d89b846a33d1,https://www.mycareersfuture.sg/job/etl-developer-etiqa-insurance-c7f5471cce4ad3ee2be6d89b846a33d1,ETL Developer,"Permanent, Contract",ETIQA INSURANCE PTE. LTD.,1 RAFFLES QUAY 048583,Senior Executive,Information Technology,4000,6000,Monthly,04 Jan 2019,1,0,0,1,"Responsibilities  Develop ETL data workflows and code for new data integrations and maintain/enhance existing data flows and packages. Familiar with IBM AS400, File, SQL, Ole-DB, ODBC providers for connect to different system or applications make data exchange. Perform data analysis and propose and ensure transformation covers all data possibilities including managing data anomalies, and exception handling. Provide support to technical team, write the necessary required documentation as per the development methodology for ETL processes, and develop unit test plan, test cases and resolve ETL related test issues. Data modeling design, according to business requires for dimension design, functions calculation. Reporting service development, store procedure or T-SQL query data. Provide in-depth troubleshooting skills to assist in resolving errors and performance issues including production support. Keep alert of integrated product developments that translate to environmental or code modifications. Comply with internal development coding standards, procedural guides, and checklists for the support of the database systems. Interacting with individuals from across the company in different supporting organizations and business groups. Ability to research, learn, troubleshoot and support complex system customizations ","Requirements  At least Bachelor’s degree in Computer Science or technology related field. At least 3 years MS SQL Server experiences, design data modelling and solutions to fulfil business and system data requirements. T-SQL development experience in SQL Server 2008 - 2016 databases, writing complex SQL (stored procedures, functions, views), Familiar SQL Server, DB2/AS400, script the Store procedure. 1 years of experience in SSIS Package Maintenance and Development, familiar with control flow and data flow development. Define, develop and sustain the database physical structure and functional capabilities, database security, data back-up, and recovery specifications Turning database performance, calculating values for database parameters to provide fast responses to end users. Support database functions by designing and coding utilities. Skillful of SQL Server development and database structures, report development with SSRS. "
122,69483206a253968d4d9dd9b499b5741c,https://www.mycareersfuture.sg/job/geospatial-specialist-developer-jtc-corporation-69483206a253968d4d9dd9b499b5741c,Geospatial Specialist  /  Developer (PDD),Permanent,JTC Corporation,"THE JTC SUMMIT, 8 JURONG TOWN HALL ROAD 609434",Unknown,"Information Technology, Public / Civil Service",,,,04 Jan 2019,0,0,0,1,"Punggol Digital District (PDD) is an upcoming mixed-use development that will house the key growth sectors of the digital economy such as cybersecurity and data analytics. It is also the first digital district in Singapore where we will integrate smart technologies horizontally on a single Open Digital Platform (ODP) to yield synergies across various technologies. The ODP will become a reference digital architecture for future smart districts in Singapore and transform the way we work, live and play. Scope and Responsibilities   We are seeking an experienced Geospatial Specialist to join our Smart Estate team to develop the Open Digital Platform’s (ODP) Geospatial related capabilities as well as Digital Twin.  As a Geospatial Specialist, you will collaborate with a technical team that comprises of Govtech, CSA, IMDA and Industry Partners to develop geospatial capabilities for an Open Digital Platform (ODP) for Smart Districts. You are to develop the GIS requirements for the ODP and work with the project team to develop ODP’s geospatial and digital twin capabilities.  Provide Geospatial expertise to the project team, including:  Geospatial Planning & Strategy – Perform geospatial visioning and strategic planning, business case development, implementation planning and risk management planning Detailed Requirement Gathering – Perform business process analysis, requirements analysis and use case analysis Architecture & Design – Develop geospatial data models and database design, system architecture design and application design Apps/System Development – Manage database development, application development, systems/Enterprise integration, quality assurance testing and configuration management Apps/System Deployment – Manage deployment planning, system installation, acceptance testing, performance validation, testing and tuning, and User Training   Perform rapid prototyping and develop geospatial models, scripts and workbenches. Ensure reusability of codes, workbenches, ETL processes and other project artefacts. Gain expertise in emerging geospatial related technologies such as 3D City Modelling, Indoor/Outdoor Positioning, AR, VR etc. Develop real-time geo-analytical models by integrating filed apps, sensors and IoT devices etc. Leverage existing central geospatial platforms and services to provide value added services and geo-enabled apps for JTC Assist in developing geospatial IT competency    Requirements   Disciplines in Geospatial Technology/Science, Computer Science/Engineering, Information Technology or equivalent   Candidates with knowledge and experience with ArcGIS and ArcGIS Urban are preferred  Minimum 6 years of relevant GIS experience in solution design, IT consulting and/or project management. Passionate about Geospatial technologies and allied emerging technologies  ",None
123,399d7e6140496b6d4f08456c8f08e618,https://www.mycareersfuture.sg/job/developer-sandbox-consulting-399d7e6140496b6d4f08456c8f08e618,Developer,Permanent,SANDBOX CONSULTING PTE. LTD.,"TRIVEX, 8 BURN ROAD 369977",Middle Management,Information Technology,4000,7500,Monthly,04 Jan 2019,0,0,0,1,Overall experience of more than 3 years implementing Oracle/Java/J2EE solutions  At least 4 years of experience implementing DM solutions using any ETL tool  Experience in data mapping between source data applications  Experience in creating detailed design documents for data migrations  Understand Data modeling and have experience working on Databases  Experience working on data migration environment is added advantage  Good understanding of Data Quality and Data Cleansing concepts.  Good communication skills and ability to work in multi-vendor environment * (Please add specific COTS/Domain experience as required),Overall experience of more than 3 years implementing Oracle/Java/J2EE solutions  At least 4 years of experience implementing DM solutions using any ETL tool  Experience in data mapping between source data applications  Experience in creating detailed design documents for data migrations  Understand Data modeling and have experience working on Databases  Experience working on data migration environment is added advantage  Good understanding of Data Quality and Data Cleansing concepts.  Good communication skills and ability to work in multi-vendor environment * (Please add specific COTS/Domain experience as required)
124,115e5ed88c3c2f64d650da84ceac6dcd,https://www.mycareersfuture.sg/job/migiration-developer-sandbox-consulting-115e5ed88c3c2f64d650da84ceac6dcd,migiration Developer,Permanent,SANDBOX CONSULTING PTE. LTD.,"TRIVEX, 8 BURN ROAD 369977",Middle Management,Information Technology,4000,9000,Monthly,04 Jan 2019,0,0,0,1,"5+ years of experience in the IT industry with experience in migration preferably in OSS/BSS domain.  Must have lead developer teams in a project, allocating work and following up to closure.  Should have extensively worked on migration projects, Understanding of relational data models on ORACLE / MS SQL server databases.  Hands on involvement in Low Level Design, Development and architecting of large Data migration projects leading developer and testing teams.  Should possess Problem solving, Team building and Leadership Skills in a fast-paced, high- growth environment.  Strong knowledge of Oracle and PLSQL programming.  Knowledge of any of the ETL tools (ODI, Informatica) is desirable.  Experience and ability to understand and interpret data migration strategies is desirable.  Should have good problem solving skills and analytical skills serving as a bridge between the architect and execution team  Ability to think through a problem and visualize the solution.  An open mind towards new challenges.  Exercise responsibility for architecture, design and documentation, adherence to software development life cycle guidelines, software version control standards and code promotion.  Exposure to Media & Entertainment, Telecom will be an added advantage.","5+ years of experience in the IT industry with experience in migration preferably in OSS/BSS domain.  Must have lead developer teams in a project, allocating work and following up to closure.  Should have extensively worked on migration projects, Understanding of relational data models on ORACLE / MS SQL server databases.  Hands on involvement in Low Level Design, Development and architecting of large Data migration projects leading developer and testing teams.  Should possess Problem solving, Team building and Leadership Skills in a fast-paced, high- growth environment.  Strong knowledge of Oracle and PLSQL programming.  Knowledge of any of the ETL tools (ODI, Informatica) is desirable.  Experience and ability to understand and interpret data migration strategies is desirable.  Should have good problem solving skills and analytical skills serving as a bridge between the architect and execution team  Ability to think through a problem and visualize the solution.  An open mind towards new challenges.  Exercise responsibility for architecture, design and documentation, adherence to software development life cycle guidelines, software version control standards and code promotion.  Exposure to Media & Entertainment, Telecom will be an added advantage."
125,9e6bb89686d7ae65bd6554890fd0ea0d,https://www.mycareersfuture.sg/job/business-analyst-government-technology-agency-9e6bb89686d7ae65bd6554890fd0ea0d,Business Analyst (Data Analytics),Full Time,GOVERNMENT TECHNOLOGY AGENCY,"MAPLETREE BUSINESS CITY, 10 PASIR PANJANG ROAD 117438",Professional,"Information Technology, Public / Civil Service",,,,09 Jul 2018,0,0,0,0,"BAF (Data Analytics) We are looking for Business Analysts (Data Analytics) who's interested in using data to help the government design solutions that address its policy and business problems, and stay close to the needs of the general public.  The applicant will be responsible for demonstrating how better use of data can help recommend new policies, streamline operations or bring more customised solutions for citizens. He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation.   What to Expect:  Provide data analytics consulting services to the government agencies, including data analytics planning and strategy – perform data analytics visioning and road-mapping, business case development, implementation planning, organisational planning, budget and risk management planning Work closely with stakeholders to understand their needs/pain points, scope the problem and develop business case on how to turn data into critical information and knowledge that can be used for policy making, streamlining operations or developing solutions for citizens.   Advise stakeholders on the key ICT trends and best practices in data analytics, assess applicability for adoption and recommend solution that best fits stakeholders’ needs Perform data cleaning, pre-processing and feature engineering that facilitate meaningful analysis Work closely with data scientists to mine insights from structured and unstructured data and to resolve complex statistical modelling problems to answer pertinent business questions.  Design dashboards and interactive visualization as tools for data exploration as well as for storytelling.  Present analytics insights to business users and stakeholders Work with stakeholders to ensure smooth deployment and adoption of new solution  How to Succeed:  Degree/Master in any discipline; Diploma graduates with relevant experience will also be considered. Minimum 3 years of relevant working experience Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges Understand key concepts, techniques and considerations in Machine learning and Data analytics Training and relevant experience in one or more of the following areas:   Statistical modelling tools such as: R, Python, RapidMiner, Knime, SAS, Matlab or SPSS Data manipulation using scripting languages like Python or using ETL tools Visual analytics technologies like Tableau, Qlikview or D3.js End-to-end analytics architecture, preferably with some working knowledge of big data stack   Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders Strong analytical, conceptualisation and problem solving skills Team player with strong organization and people handling skills Passion for the use of analytics and data to improve public service ",None
